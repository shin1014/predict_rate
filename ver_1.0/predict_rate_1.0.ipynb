{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力はNY(-13h)で行う。これにより最新のレートが取得できる。\n",
      "ただし、indexに出力されるのはGMT(-9h)である。\n",
      "JPN: 2020-10-06 18:01:36.664238\n",
      "NY: 2020-10-04 22:21:35.664238 2020-10-05 05:01:35.664238\n",
      "GMT(index): 2020-10-05 02:21:35.664238 2020-10-05 09:01:35.664238\n",
      "                     January  February  March  April  May  June  July  August  \\\n",
      "Datetime                                                                        \n",
      "2020-10-05 02:20:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 02:30:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 02:40:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 02:50:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 03:00:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 03:10:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 03:20:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 03:30:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 03:40:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 03:50:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 04:00:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 04:10:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 04:20:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 04:30:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 04:40:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 04:50:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 05:00:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 05:10:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 05:20:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 05:30:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 05:40:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 05:50:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 06:00:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 06:10:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 06:20:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 06:30:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 06:40:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 06:50:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 07:00:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 07:10:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 07:20:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 07:30:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 07:40:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 07:50:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 08:00:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 08:10:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 08:20:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 08:30:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 08:40:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 08:50:00        0         0      0      0    0     0     0       0   \n",
      "2020-10-05 09:00:00        0         0      0      0    0     0     0       0   \n",
      "\n",
      "                     September  October  ...  Thuesday  Wednesday  Thursday  \\\n",
      "Datetime                                 ...                                  \n",
      "2020-10-05 02:20:00          0        1  ...         0          0         0   \n",
      "2020-10-05 02:30:00          0        1  ...         0          0         0   \n",
      "2020-10-05 02:40:00          0        1  ...         0          0         0   \n",
      "2020-10-05 02:50:00          0        1  ...         0          0         0   \n",
      "2020-10-05 03:00:00          0        1  ...         0          0         0   \n",
      "2020-10-05 03:10:00          0        1  ...         0          0         0   \n",
      "2020-10-05 03:20:00          0        1  ...         0          0         0   \n",
      "2020-10-05 03:30:00          0        1  ...         0          0         0   \n",
      "2020-10-05 03:40:00          0        1  ...         0          0         0   \n",
      "2020-10-05 03:50:00          0        1  ...         0          0         0   \n",
      "2020-10-05 04:00:00          0        1  ...         0          0         0   \n",
      "2020-10-05 04:10:00          0        1  ...         0          0         0   \n",
      "2020-10-05 04:20:00          0        1  ...         0          0         0   \n",
      "2020-10-05 04:30:00          0        1  ...         0          0         0   \n",
      "2020-10-05 04:40:00          0        1  ...         0          0         0   \n",
      "2020-10-05 04:50:00          0        1  ...         0          0         0   \n",
      "2020-10-05 05:00:00          0        1  ...         0          0         0   \n",
      "2020-10-05 05:10:00          0        1  ...         0          0         0   \n",
      "2020-10-05 05:20:00          0        1  ...         0          0         0   \n",
      "2020-10-05 05:30:00          0        1  ...         0          0         0   \n",
      "2020-10-05 05:40:00          0        1  ...         0          0         0   \n",
      "2020-10-05 05:50:00          0        1  ...         0          0         0   \n",
      "2020-10-05 06:00:00          0        1  ...         0          0         0   \n",
      "2020-10-05 06:10:00          0        1  ...         0          0         0   \n",
      "2020-10-05 06:20:00          0        1  ...         0          0         0   \n",
      "2020-10-05 06:30:00          0        1  ...         0          0         0   \n",
      "2020-10-05 06:40:00          0        1  ...         0          0         0   \n",
      "2020-10-05 06:50:00          0        1  ...         0          0         0   \n",
      "2020-10-05 07:00:00          0        1  ...         0          0         0   \n",
      "2020-10-05 07:10:00          0        1  ...         0          0         0   \n",
      "2020-10-05 07:20:00          0        1  ...         0          0         0   \n",
      "2020-10-05 07:30:00          0        1  ...         0          0         0   \n",
      "2020-10-05 07:40:00          0        1  ...         0          0         0   \n",
      "2020-10-05 07:50:00          0        1  ...         0          0         0   \n",
      "2020-10-05 08:00:00          0        1  ...         0          0         0   \n",
      "2020-10-05 08:10:00          0        1  ...         0          0         0   \n",
      "2020-10-05 08:20:00          0        1  ...         0          0         0   \n",
      "2020-10-05 08:30:00          0        1  ...         0          0         0   \n",
      "2020-10-05 08:40:00          0        1  ...         0          0         0   \n",
      "2020-10-05 08:50:00          0        1  ...         0          0         0   \n",
      "2020-10-05 09:00:00          0        1  ...         0          0         0   \n",
      "\n",
      "                     Friday  Saturday  Volume     Open     High      Low  \\\n",
      "Datetime                                                                   \n",
      "2020-10-05 02:20:00       0         0     244  105.538  105.549  105.532   \n",
      "2020-10-05 02:30:00       0         0     427  105.532  105.564  105.532   \n",
      "2020-10-05 02:40:00       0         0     625  105.560  105.562  105.546   \n",
      "2020-10-05 02:50:00       0         0     446  105.551  105.562  105.536   \n",
      "2020-10-05 03:00:00       0         0     399  105.554  105.558  105.542   \n",
      "2020-10-05 03:10:00       0         0     270  105.546  105.556  105.538   \n",
      "2020-10-05 03:20:00       0         0     176  105.548  105.548  105.534   \n",
      "2020-10-05 03:30:00       0         0     125  105.542  105.548  105.527   \n",
      "2020-10-05 03:40:00       0         0     249  105.528  105.534  105.510   \n",
      "2020-10-05 03:50:00       0         0     386  105.535  105.541  105.522   \n",
      "2020-10-05 04:00:00       0         0     318  105.530  105.552  105.520   \n",
      "2020-10-05 04:10:00       0         0     608  105.549  105.560  105.544   \n",
      "2020-10-05 04:20:00       0         0     575  105.548  105.550  105.526   \n",
      "2020-10-05 04:30:00       0         0     293  105.546  105.556  105.542   \n",
      "2020-10-05 04:40:00       0         0     334  105.554  105.564  105.547   \n",
      "2020-10-05 04:50:00       0         0     378  105.560  105.566  105.538   \n",
      "2020-10-05 05:00:00       0         0     337  105.564  105.575  105.554   \n",
      "2020-10-05 05:10:00       0         0     321  105.574  105.584  105.564   \n",
      "2020-10-05 05:20:00       0         0     292  105.579  105.584  105.566   \n",
      "2020-10-05 05:30:00       0         0     264  105.568  105.582  105.558   \n",
      "2020-10-05 05:40:00       0         0     384  105.563  105.574  105.548   \n",
      "2020-10-05 05:50:00       0         0     387  105.571  105.572  105.560   \n",
      "2020-10-05 06:00:00       0         0     735  105.571  105.597  105.565   \n",
      "2020-10-05 06:10:00       0         0     389  105.570  105.589  105.566   \n",
      "2020-10-05 06:20:00       0         0     211  105.584  105.590  105.579   \n",
      "2020-10-05 06:30:00       0         0     340  105.586  105.602  105.578   \n",
      "2020-10-05 06:40:00       0         0     242  105.592  105.603  105.583   \n",
      "2020-10-05 06:50:00       0         0     284  105.590  105.625  105.587   \n",
      "2020-10-05 07:00:00       0         0     721  105.624  105.639  105.602   \n",
      "2020-10-05 07:10:00       0         0     701  105.608  105.617  105.562   \n",
      "2020-10-05 07:20:00       0         0     599  105.592  105.608  105.580   \n",
      "2020-10-05 07:30:00       0         0     411  105.598  105.616  105.592   \n",
      "2020-10-05 07:40:00       0         0     583  105.604  105.634  105.604   \n",
      "2020-10-05 07:50:00       0         0     668  105.614  105.616  105.578   \n",
      "2020-10-05 08:00:00       0         0     696  105.606  105.638  105.588   \n",
      "2020-10-05 08:10:00       0         0     941  105.622  105.676  105.618   \n",
      "2020-10-05 08:20:00       0         0     668  105.671  105.680  105.648   \n",
      "2020-10-05 08:30:00       0         0     469  105.664  105.676  105.638   \n",
      "2020-10-05 08:40:00       0         0     363  105.658  105.668  105.639   \n",
      "2020-10-05 08:50:00       0         0     336  105.646  105.653  105.636   \n",
      "2020-10-05 09:00:00       0         0     426  105.638  105.640  105.619   \n",
      "\n",
      "                       Close  \n",
      "Datetime                      \n",
      "2020-10-05 02:20:00  105.533  \n",
      "2020-10-05 02:30:00  105.561  \n",
      "2020-10-05 02:40:00  105.552  \n",
      "2020-10-05 02:50:00  105.553  \n",
      "2020-10-05 03:00:00  105.544  \n",
      "2020-10-05 03:10:00  105.549  \n",
      "2020-10-05 03:20:00  105.541  \n",
      "2020-10-05 03:30:00  105.527  \n",
      "2020-10-05 03:40:00  105.534  \n",
      "2020-10-05 03:50:00  105.528  \n",
      "2020-10-05 04:00:00  105.550  \n",
      "2020-10-05 04:10:00  105.548  \n",
      "2020-10-05 04:20:00  105.544  \n",
      "2020-10-05 04:30:00  105.552  \n",
      "2020-10-05 04:40:00  105.558  \n",
      "2020-10-05 04:50:00  105.562  \n",
      "2020-10-05 05:00:00  105.575  \n",
      "2020-10-05 05:10:00  105.580  \n",
      "2020-10-05 05:20:00  105.568  \n",
      "2020-10-05 05:30:00  105.564  \n",
      "2020-10-05 05:40:00  105.570  \n",
      "2020-10-05 05:50:00  105.570  \n",
      "2020-10-05 06:00:00  105.572  \n",
      "2020-10-05 06:10:00  105.585  \n",
      "2020-10-05 06:20:00  105.584  \n",
      "2020-10-05 06:30:00  105.591  \n",
      "2020-10-05 06:40:00  105.588  \n",
      "2020-10-05 06:50:00  105.622  \n",
      "2020-10-05 07:00:00  105.607  \n",
      "2020-10-05 07:10:00  105.591  \n",
      "2020-10-05 07:20:00  105.597  \n",
      "2020-10-05 07:30:00  105.604  \n",
      "2020-10-05 07:40:00  105.613  \n",
      "2020-10-05 07:50:00  105.608  \n",
      "2020-10-05 08:00:00  105.621  \n",
      "2020-10-05 08:10:00  105.670  \n",
      "2020-10-05 08:20:00  105.664  \n",
      "2020-10-05 08:30:00  105.656  \n",
      "2020-10-05 08:40:00  105.646  \n",
      "2020-10-05 08:50:00  105.637  \n",
      "2020-10-05 09:00:00  105.636  \n",
      "\n",
      "[41 rows x 25 columns]\n",
      "[0, 24, 5]\n",
      "                     January  February  March  April  May  June  July  August  \\\n",
      "Datetime                                                                        \n",
      "2020-10-05 09:00:00      0.0       0.0    0.0    0.0  0.0   0.0   0.0     0.0   \n",
      "\n",
      "                     September  October  ...  SMA_hour/current  \\\n",
      "Datetime                                 ...                     \n",
      "2020-10-05 09:00:00        0.0      1.0  ...          1.000147   \n",
      "\n",
      "                     SMA_2hour/current        RSI      MACD  BBANDS+2σ  \\\n",
      "Datetime                                                                 \n",
      "2020-10-05 09:00:00            0.99993  60.355954  0.019964   1.000616   \n",
      "\n",
      "                     BBANDS-2σ  10m_rate  30m_rate  60m_rate  120m_rate  \n",
      "Datetime                                                                 \n",
      "2020-10-05 09:00:00   0.998951 -0.000947 -0.018929  0.014202    0.02746  \n",
      "\n",
      "[1 rows x 30 columns]                      class\n",
      "Datetime                  \n",
      "2020-10-05 09:00:00    NaN\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 9 and input n_features is 30 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-701f2370c5c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;31m#print(result)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_now\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\predict_rate\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \"\"\"\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\predict_rate\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\predict_rate\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\predict_rate\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[0;32m    397\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 9 and input n_features is 30 "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from oandapyV20 import API\n",
    "from oandapyV20.exceptions import V20Error\n",
    "from oandapyV20.endpoints.pricing import PricingStream\n",
    "import oandapyV20.endpoints.orders as orders\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "import talib as ta\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "#自分のアカウント、トークンをセット\n",
    "accountID = \"101-009-16415310-001\"\n",
    "access_token = '860c2d2dbbcd01b6d95939b6af6b5981-8664724ce0870220c55161d704137df6'\n",
    "\n",
    "api = API(access_token=access_token, environment=\"practice\")\n",
    "\n",
    "# year_months =[ [2016, 1], [2016, 2], [2016, 3], [2016, 4], [2016, 5], [2016, 6], [2016, 7], [2016, 8], [2016, 9], [2016, 10], [2016, 11], [2016, 12],\n",
    "#     [2017, 1], [2017, 2], [2017, 3], [2017, 4], [2017, 5], [2017, 6], [2017, 7], [2017, 8], [2017, 9], [2017, 10], [2017, 11], [2017, 12],\n",
    "#     [2018, 1], [2018, 2], [2018, 3], [2018, 4], [2018, 5], [2018, 6], [2018, 7], [2018, 8], [2018, 9], [2018, 10], [2018, 11], [2018, 12],[2019, 1], [2019, 2], [2019, 3], [2019, 4], [2019, 5], [2019, 6], [2019, 7]]\n",
    "\n",
    "## Oandaからcandleデータを取得する。 時差のため、現在のレート取得のため、-9h\n",
    "def getCandleDataFromOanda(instrument, api, date_from, date_to, granularity):\n",
    "    params = {\n",
    "        \"from\": date_from.isoformat(),\n",
    "        \"to\": date_to.isoformat(),\n",
    "        \"granularity\": granularity,\n",
    "    }\n",
    "    r = instruments.InstrumentsCandles(instrument=instrument, params=params)\n",
    "    return api.request(r)\n",
    "\n",
    "def oandaJsonToPythonList(JSONRes):\n",
    "    \n",
    "    #adjust = datetime.timedelta(hours=-4)\n",
    "    \n",
    "    \n",
    "    data = []\n",
    "    for res in JSONRes['candles']:\n",
    "        temp = [datetime.datetime.fromisoformat(res['time'][:19])]\n",
    "        \n",
    "        for i in range(1,13):\n",
    "           \n",
    "            if(datetime.datetime.fromisoformat(res['time'][:19]).month==i):\n",
    "                temp.extend([1]) #月をonehotで追加\n",
    "                #time.sleep(0.1)\n",
    "            else:\n",
    "                temp.extend([0])\n",
    "                \n",
    "        temp.extend([datetime.datetime.fromisoformat(res['time'][:19]).day])  #日を追加\n",
    "        \n",
    "        for i in range(0,7):\n",
    "            \n",
    "            if(datetime.datetime.fromisoformat(res['time'][:19]).weekday==i):\n",
    "                temp.extend([1]) #曜日をonehotで追加\n",
    "                #time.sleep(0.00001)\n",
    "            else:\n",
    "                temp.extend([0])\n",
    "        \n",
    "        temp.extend([res['volume'],\n",
    "            res['mid']['o'],\n",
    "            res['mid']['h'],\n",
    "            res['mid']['l'],\n",
    "            res['mid']['c'],\n",
    "            ])\n",
    "        data.append(temp)\n",
    "    return data\n",
    "\n",
    "all_data = []\n",
    "# year, monthでループ\n",
    "#for year, month in year_months:\n",
    "\n",
    "NY = datetime.timedelta(hours=-13) + datetime.timedelta(seconds=-1)#レートは時差を考慮して取得\n",
    "\n",
    "# -13hしないと\"This time is future\"となることから、入力した時間はNY時間として認識される。\n",
    "\n",
    "\n",
    "bias = datetime.timedelta(days=-1)\n",
    "\n",
    "\n",
    "date_from = datetime.datetime.now() + NY + datetime.timedelta(minutes=-400) + bias\n",
    "date_to =  datetime.datetime.now() + NY +bias\n",
    "\n",
    "print(\"入力はNY(-13h)で行う。これにより最新のレートが取得できる。\")\n",
    "print(\"ただし、indexに出力されるのはGMT(-9h)である。\")\n",
    "print(\"JPN: \"+str(datetime.datetime.now()))\n",
    "print(\"NY: \"+str(date_from)+\" \"+str(date_to))\n",
    "print(\"GMT(index): \"+str(date_from+datetime.timedelta(hours=4))+\" \"+str(date_to+datetime.timedelta(hours=4)))\n",
    "\n",
    "ret = getCandleDataFromOanda(\"USD_JPY\", api, date_from, date_to, \"M10\")\n",
    "twohours_data = oandaJsonToPythonList(ret)#取得したデータを格納\n",
    "\n",
    "\n",
    "\n",
    "all_data.extend(twohours_data)#データを追加\n",
    "\n",
    "#print(all_data)\n",
    "\n",
    "#ここからall_dataに追加すればよい\n",
    "\n",
    "\n",
    "# pandas DataFrameへ変換\n",
    "now_df = pd.DataFrame(all_data)\n",
    "now_df.columns = ['Datetime',\n",
    "              \"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\",\n",
    "              \"day\",\n",
    "              \"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\n",
    "              'Volume', 'Open', 'High', 'Low', 'Close']\n",
    "now_df = now_df.set_index('Datetime')\n",
    "\n",
    "print(now_df)\n",
    "\n",
    "def adjust_data(df):\n",
    "    \n",
    "    df = df.astype(float)\n",
    "    \n",
    "    #以降全ての計算でレート終値を使う\n",
    "    close = np.array(df[\"Close\"])\n",
    "    \n",
    "    \n",
    "    #特徴量を入れるための空のdataframeを作成\n",
    "    df_feature = pd.DataFrame(columns=[ \n",
    "        \"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\n",
    "        \"July\",\"August\",\"September\",\"October\",\"November\",\"December\",\n",
    "        \"day\",\n",
    "        \"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\n",
    "        \"SMA_hour/current\",\n",
    "        \"SMA_2hour/current\",\n",
    "        \"RSI\",\n",
    "        \"MACD\",\n",
    "        \"BBANDS+2σ\",\n",
    "        \"BBANDS-2σ\",\n",
    "        \"10m_rate\",\n",
    "        \"30m_rate\",\n",
    "        \"60m_rate\",\n",
    "        \"120m_rate\"\n",
    "        ])\n",
    "\n",
    "\n",
    "    df_feature[\"January\"] = df[\"January\"]\n",
    "    df_feature[\"February\"] = df[\"February\"]\n",
    "    df_feature[\"March\"] = df[\"March\"]\n",
    "    df_feature[\"April\"] = df[\"April\"]\n",
    "    df_feature[\"May\"] = df[\"May\"]\n",
    "    df_feature[\"June\"] = df[\"June\"]\n",
    "    df_feature[\"July\"] = df[\"July\"]\n",
    "    df_feature[\"August\"] = df[\"August\"]\n",
    "    df_feature[\"September\"] = df[\"September\"]\n",
    "    df_feature[\"October\"] = df[\"October\"]\n",
    "    df_feature[\"November\"] = df[\"November\"]\n",
    "    df_feature[\"December\"] = df[\"December\"]\n",
    "    \n",
    "    #print(df_feature.isnull().any())\n",
    "    \n",
    "    #print(df_feature.isnull().any())\n",
    "    \n",
    "#     days=[\"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"]\n",
    "#     for i in days:\n",
    "#         df_feature[i] = df[i]\n",
    "\n",
    "    df_feature[\"Sunday\"] = df[\"Sunday\"]\n",
    "    df_feature[\"Monday\"] = df[\"Monday\"]\n",
    "    df_feature[\"Thuesday\"] = df[\"Thuesday\"]\n",
    "    df_feature[\"Wednesday\"] = df[\"Wednesday\"]\n",
    "    df_feature[\"Thursday\"] = df[\"Thursday\"]\n",
    "    df_feature[\"Friday\"] = df[\"Friday\"]\n",
    "    df_feature[\"Saturday\"] = df[\"Saturday\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_feature[\"day\"] = df[\"day\"]\n",
    "    df_feature[\"10m_rate\"] = df[\"Close\"].astype(float).pct_change()*100\n",
    "    df_feature[\"30m_rate\"] = df[\"Close\"].astype(float).pct_change(3)*100\n",
    "    df_feature[\"60m_rate\"] = df[\"Close\"].astype(float).pct_change(6)*100\n",
    "    df_feature[\"120m_rate\"] = df[\"Close\"].astype(float).pct_change(12)*100\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #以下、talibを用いてテクニカル指標（今回の学習で用いる特徴量）を算出しdf_feature入れる\n",
    "\n",
    "    #単純移動平均は、単純移動平均値とその日の終値の比を特徴量として用いる\n",
    "    df_feature[\"SMA_hour/current\"]= ta.SMA(close, timeperiod=6) / close\n",
    "    df_feature[\"SMA_2hour/current\"]= ta.SMA(close, timeperiod=12) / close\n",
    "\n",
    "    #RSI\n",
    "    df_feature[\"RSI\"] = ta.RSI(close, timeperiod=12)\n",
    "\n",
    "    #MACD\n",
    "    df_feature[\"MACD\"], _ , _= ta.MACD(close, fastperiod=3, slowperiod=18, signalperiod=9)\n",
    "\n",
    "    #ボリンジャーバンド \n",
    "    upper, middle, lower = ta.BBANDS(close, timeperiod=20, nbdevup=3, nbdevdn=3)\n",
    "    df_feature[\"BBANDS+2σ\"] = upper / close\n",
    "    df_feature[\"BBANDS-2σ\"] = lower / close\n",
    "\n",
    "    \n",
    "    \n",
    "    c=[0,0,0]\n",
    "    \n",
    "    def classify(x):\n",
    "        percent = 0.05\n",
    "\n",
    "        if x<-percent:\n",
    "            c[0]+=1\n",
    "            return 0\n",
    "        elif -percent<x<percent:\n",
    "            c[1]+=1\n",
    "            return 1\n",
    "        elif percent<x:\n",
    "            c[2]+=1\n",
    "            return 2\n",
    "\n",
    "    classified = pd.DataFrame(columns=[\"class\"])\n",
    "    classified[\"class\"] = df_feature[\"120m_rate\"].apply(lambda x: classify(x))\n",
    "\n",
    "    classified = classified.shift(-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     df_adjusted=df_feature[30:len(df_feature)-1]\n",
    "#     classified=classified[30:len(classified)-1]\n",
    "    \n",
    "    df_adjusted=df_feature.tail(1)\n",
    "    classified=classified.tail(1)\n",
    "    \n",
    "    print(c)\n",
    "    \n",
    "    print(df_adjusted, classified)\n",
    "    \n",
    "    return df_adjusted, classified\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "\n",
    "filename = 'RF_01.sav'\n",
    "\n",
    "X_now, y_now = adjust_data(now_df)\n",
    "\n",
    "#print(X_now, y_now)\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#result = loaded_model.score(X_now, y_now)\n",
    "\n",
    "#print(result)\n",
    "\n",
    "print(loaded_model.predict(X_now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力はNY(-13h)で行う。これにより最新のレートが取得できる。\n",
      "ただし、indexに出力されるのはGMT(-9h)である。\n",
      "JPN: 2020-10-04 22:02:33.203607\n",
      "NY: 2020-10-02 16:22:32.203607 2020-10-03 09:02:32.203607\n",
      "GMT(index): 2020-10-02 20:22:32.203607 2020-10-03 13:02:32.203607\n",
      "[0, 0, 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7509649ce894>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_now\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnow_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-7509649ce894>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(now_df, filename)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_now\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m49\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_now\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m49\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_now\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\predict_rate\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \"\"\"\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\predict_rate\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\predict_rate\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\predict_rate\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    390\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m~\\.conda\\envs\\predict_rate\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\predict_rate\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\predict_rate\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from oandapyV20 import API\n",
    "from oandapyV20.exceptions import V20Error\n",
    "from oandapyV20.endpoints.pricing import PricingStream\n",
    "import oandapyV20.endpoints.orders as orders\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "import talib as ta\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "#自分のアカウント、トークンをセット\n",
    "accountID = \"101-009-16415310-001\"\n",
    "access_token = '860c2d2dbbcd01b6d95939b6af6b5981-8664724ce0870220c55161d704137df6'\n",
    "\n",
    "api = API(access_token=access_token, environment=\"practice\")\n",
    "\n",
    "# year_months =[ [2016, 1], [2016, 2], [2016, 3], [2016, 4], [2016, 5], [2016, 6], [2016, 7], [2016, 8], [2016, 9], [2016, 10], [2016, 11], [2016, 12],\n",
    "#     [2017, 1], [2017, 2], [2017, 3], [2017, 4], [2017, 5], [2017, 6], [2017, 7], [2017, 8], [2017, 9], [2017, 10], [2017, 11], [2017, 12],\n",
    "#     [2018, 1], [2018, 2], [2018, 3], [2018, 4], [2018, 5], [2018, 6], [2018, 7], [2018, 8], [2018, 9], [2018, 10], [2018, 11], [2018, 12],[2019, 1], [2019, 2], [2019, 3], [2019, 4], [2019, 5], [2019, 6], [2019, 7]]\n",
    "\n",
    "## Oandaからcandleデータを取得する。 時差のため、現在のレート取得のため、-9h\n",
    "def getCandleDataFromOanda(instrument, api, date_from, date_to, granularity):\n",
    "    params = {\n",
    "        \"from\": date_from.isoformat(),\n",
    "        \"to\": date_to.isoformat(),\n",
    "        \"granularity\": granularity,\n",
    "    }\n",
    "    r = instruments.InstrumentsCandles(instrument=instrument, params=params)\n",
    "    return api.request(r)\n",
    "\n",
    "def oandaJsonToPythonList(JSONRes):\n",
    "    \n",
    "    #adjust = datetime.timedelta(hours=-4)\n",
    "    \n",
    "    \n",
    "    data = []\n",
    "    for res in JSONRes['candles']:\n",
    "        temp = [datetime.datetime.fromisoformat(res['time'][:19])]\n",
    "        \n",
    "        for i in range(1,13):\n",
    "           \n",
    "            if(datetime.datetime.fromisoformat(res['time'][:19]).month==i):\n",
    "                temp.extend([1]) #月をonehotで追加\n",
    "                #time.sleep(0.1)\n",
    "            else:\n",
    "                temp.extend([0])\n",
    "                \n",
    "        temp.extend([datetime.datetime.fromisoformat(res['time'][:19]).day])  #日を追加\n",
    "        \n",
    "        for i in range(0,7):\n",
    "            \n",
    "            if(datetime.datetime.fromisoformat(res['time'][:19]).weekday==i):\n",
    "                temp.extend([1]) #曜日をonehotで追加\n",
    "                #time.sleep(0.00001)\n",
    "            else:\n",
    "                temp.extend([0])\n",
    "        \n",
    "        temp.extend([res['volume'],\n",
    "            res['mid']['o'],\n",
    "            res['mid']['h'],\n",
    "            res['mid']['l'],\n",
    "            res['mid']['c'],\n",
    "            ])\n",
    "        data.append(temp)\n",
    "    return data\n",
    "\n",
    "all_data = []\n",
    "# year, monthでループ\n",
    "#for year, month in year_months:\n",
    "\n",
    "NY = datetime.timedelta(hours=-13) + datetime.timedelta(seconds=-1)#レートは時差を考慮して取得\n",
    "\n",
    "# -13hしないと\"This time is future\"となることから、入力した時間はNY時間として認識される。\n",
    "\n",
    "\n",
    "bias = datetime.timedelta(days=-1)\n",
    "\n",
    "\n",
    "date_from = datetime.datetime.now() + NY + datetime.timedelta(minutes=-1000) + bias\n",
    "date_to =  datetime.datetime.now() + NY +bias\n",
    "\n",
    "print(\"入力はNY(-13h)で行う。これにより最新のレートが取得できる。\")\n",
    "print(\"ただし、indexに出力されるのはGMT(-9h)である。\")\n",
    "print(\"JPN: \"+str(datetime.datetime.now()))\n",
    "print(\"NY: \"+str(date_from)+\" \"+str(date_to))\n",
    "print(\"GMT(index): \"+str(date_from+datetime.timedelta(hours=4))+\" \"+str(date_to+datetime.timedelta(hours=4)))\n",
    "\n",
    "ret = getCandleDataFromOanda(\"USD_JPY\", api, date_from, date_to, \"M10\")\n",
    "twohours_data = oandaJsonToPythonList(ret)#取得したデータを格納\n",
    "\n",
    "\n",
    "\n",
    "all_data.extend(twohours_data)#データを追加\n",
    "\n",
    "#print(all_data)\n",
    "\n",
    "#ここからall_dataに追加すればよい\n",
    "\n",
    "\n",
    "# pandas DataFrameへ変換\n",
    "now_df = pd.DataFrame(all_data)\n",
    "now_df.columns = ['Datetime',\n",
    "              \"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\",\n",
    "              \"day\",\n",
    "              \"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\n",
    "              'Volume', 'Open', 'High', 'Low', 'Close']\n",
    "now_df = now_df.set_index('Datetime')\n",
    "\n",
    "#print(now_df)\n",
    "\n",
    "def adjust_now_data(df, num=1):\n",
    "    \n",
    "    df = df.astype(float)\n",
    "    \n",
    "    #以降全ての計算でレート終値を使う\n",
    "    close = np.array(df[\"Close\"])\n",
    "    \n",
    "    \n",
    "    #特徴量を入れるための空のdataframeを作成\n",
    "    df_feature = pd.DataFrame(columns=[ \n",
    "        \"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\n",
    "        \"July\",\"August\",\"September\",\"October\",\"November\",\"December\",\n",
    "        \"day\",\n",
    "        \"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\n",
    "        \"SMA_hour/current\",\n",
    "        \"SMA_2hour/current\",\n",
    "        \"RSI\",\n",
    "        \"MACD\",\n",
    "        \"BBANDS+2σ\",\n",
    "        \"BBANDS-2σ\",\n",
    "        \"10m_rate\",\n",
    "        \"30m_rate\",\n",
    "        \"60m_rate\",\n",
    "        \"120m_rate\"\n",
    "        ])\n",
    "\n",
    "\n",
    "    df_feature[\"January\"] = df[\"January\"]\n",
    "    df_feature[\"February\"] = df[\"February\"]\n",
    "    df_feature[\"March\"] = df[\"March\"]\n",
    "    df_feature[\"April\"] = df[\"April\"]\n",
    "    df_feature[\"May\"] = df[\"May\"]\n",
    "    df_feature[\"June\"] = df[\"June\"]\n",
    "    df_feature[\"July\"] = df[\"July\"]\n",
    "    df_feature[\"August\"] = df[\"August\"]\n",
    "    df_feature[\"September\"] = df[\"September\"]\n",
    "    df_feature[\"October\"] = df[\"October\"]\n",
    "    df_feature[\"November\"] = df[\"November\"]\n",
    "    df_feature[\"December\"] = df[\"December\"]\n",
    "    \n",
    "    #print(df_feature.isnull().any())\n",
    "    \n",
    "    #print(df_feature.isnull().any())\n",
    "    \n",
    "#     days=[\"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"]\n",
    "#     for i in days:\n",
    "#         df_feature[i] = df[i]\n",
    "\n",
    "    df_feature[\"Sunday\"] = df[\"Sunday\"]\n",
    "    df_feature[\"Monday\"] = df[\"Monday\"]\n",
    "    df_feature[\"Thuesday\"] = df[\"Thuesday\"]\n",
    "    df_feature[\"Wednesday\"] = df[\"Wednesday\"]\n",
    "    df_feature[\"Thursday\"] = df[\"Thursday\"]\n",
    "    df_feature[\"Friday\"] = df[\"Friday\"]\n",
    "    df_feature[\"Saturday\"] = df[\"Saturday\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_feature[\"day\"] = df[\"day\"]\n",
    "    df_feature[\"10m_rate\"] = df[\"Close\"].astype(float).pct_change()*100\n",
    "    df_feature[\"30m_rate\"] = df[\"Close\"].astype(float).pct_change(3)*100\n",
    "    df_feature[\"60m_rate\"] = df[\"Close\"].astype(float).pct_change(6)*100\n",
    "    df_feature[\"120m_rate\"] = df[\"Close\"].astype(float).pct_change(12)*100\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #以下、talibを用いてテクニカル指標（今回の学習で用いる特徴量）を算出しdf_feature入れる\n",
    "\n",
    "    #単純移動平均は、単純移動平均値とその日の終値の比を特徴量として用いる\n",
    "    df_feature[\"SMA_hour/current\"]= ta.SMA(close, timeperiod=6) / close\n",
    "    df_feature[\"SMA_2hour/current\"]= ta.SMA(close, timeperiod=12) / close\n",
    "\n",
    "    #RSI\n",
    "    df_feature[\"RSI\"] = ta.RSI(close, timeperiod=12)\n",
    "\n",
    "    #MACD\n",
    "    df_feature[\"MACD\"], _ , _= ta.MACD(close, fastperiod=3, slowperiod=18, signalperiod=9)\n",
    "\n",
    "    #ボリンジャーバンド \n",
    "    upper, middle, lower = ta.BBANDS(close, timeperiod=20, nbdevup=3, nbdevdn=3)\n",
    "    df_feature[\"BBANDS+2σ\"] = upper / close\n",
    "    df_feature[\"BBANDS-2σ\"] = lower / close\n",
    "\n",
    "    \n",
    "    \n",
    "    c=[0,0,0]\n",
    "    \n",
    "    def classify(x):\n",
    "        percent = 0.05\n",
    "\n",
    "        if x<-percent:\n",
    "            c[0]+=1\n",
    "            return 0\n",
    "        elif -percent<x<percent:\n",
    "            c[1]+=1\n",
    "            return 1\n",
    "        elif percent<x:\n",
    "            c[2]+=1\n",
    "            return 2\n",
    "\n",
    "    classified = pd.DataFrame(columns=[\"class\"])\n",
    "    classified[\"class\"] = df_feature[\"120m_rate\"].apply(lambda x: classify(x))\n",
    "\n",
    "    classified = classified.shift(-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     df_adjusted=df_feature[30:len(df_feature)-1]\n",
    "#     classified=classified[30:len(classified)-1]\n",
    "    \n",
    "    df_adjusted=df_feature.tail(num)\n",
    "    classified=classified.tail(num)\n",
    "    \n",
    "    print(c)\n",
    "    \n",
    "    #print(df_adjusted, classified)\n",
    "    \n",
    "    return df_adjusted, classified\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "def predict(now_df, filename = 'RF_01.sav'):\n",
    "    X_now, y_now = adjust_now_data(now_df, 50)\n",
    "\n",
    "    #print(X_now, y_now)\n",
    "\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    #result = loaded_model.score(X_now, y_now)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(loaded_model.predict(X_now)[:49], y_now[\"class\"].values[:49]))\n",
    "    \n",
    "    return loaded_model.predict(X_now)\n",
    "\n",
    "predict(now_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力はNY(-13h)で行う。これにより最新のレートが取得できる。\n",
      "ただし、indexに出力されるのはGMT(-9h)である。\n",
      "JPN: 2020-10-04 22:14:24.826215\n",
      "NY: 2020-10-01 07:14:23.824216 2020-10-03 09:14:23.825215\n",
      "GMT(index): 2020-10-01 11:14:23.824216 2020-10-03 13:14:23.825215\n",
      "[32, 112, 47]\n",
      "0.5113636363636364\n",
      "[0.33333333 0.7        0.23076923]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 2., 0., 2., 2., 2., 1., 2., 1., 1., 1., 1., 1., 2.,\n",
       "       0., 0., 0., 0., 2., 2., 1., 0., 1., 1., 0., 1., 1., 2., 1., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 2., 2., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 2., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from oandapyV20 import API\n",
    "from oandapyV20.exceptions import V20Error\n",
    "from oandapyV20.endpoints.pricing import PricingStream\n",
    "import oandapyV20.endpoints.orders as orders\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "import talib as ta\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "#自分のアカウント、トークンをセット\n",
    "accountID = \"101-009-16415310-001\"\n",
    "access_token = '860c2d2dbbcd01b6d95939b6af6b5981-8664724ce0870220c55161d704137df6'\n",
    "\n",
    "api = API(access_token=access_token, environment=\"practice\")\n",
    "\n",
    "# year_months =[ [2016, 1], [2016, 2], [2016, 3], [2016, 4], [2016, 5], [2016, 6], [2016, 7], [2016, 8], [2016, 9], [2016, 10], [2016, 11], [2016, 12],\n",
    "#     [2017, 1], [2017, 2], [2017, 3], [2017, 4], [2017, 5], [2017, 6], [2017, 7], [2017, 8], [2017, 9], [2017, 10], [2017, 11], [2017, 12],\n",
    "#     [2018, 1], [2018, 2], [2018, 3], [2018, 4], [2018, 5], [2018, 6], [2018, 7], [2018, 8], [2018, 9], [2018, 10], [2018, 11], [2018, 12],[2019, 1], [2019, 2], [2019, 3], [2019, 4], [2019, 5], [2019, 6], [2019, 7]]\n",
    "\n",
    "## Oandaからcandleデータを取得する。 時差のため、現在のレート取得のため、-9h\n",
    "def getCandleDataFromOanda(instrument, api, date_from, date_to, granularity):\n",
    "    params = {\n",
    "        \"from\": date_from.isoformat(),\n",
    "        \"to\": date_to.isoformat(),\n",
    "        \"granularity\": granularity,\n",
    "    }\n",
    "    r = instruments.InstrumentsCandles(instrument=instrument, params=params)\n",
    "    return api.request(r)\n",
    "\n",
    "def oandaJsonToPythonList(JSONRes):\n",
    "    \n",
    "    #adjust = datetime.timedelta(hours=-4)\n",
    "    \n",
    "    \n",
    "    data = []\n",
    "    for res in JSONRes['candles']:\n",
    "        temp = [datetime.datetime.fromisoformat(res['time'][:19])]\n",
    "        \n",
    "        for i in range(1,13):\n",
    "           \n",
    "            if(datetime.datetime.fromisoformat(res['time'][:19]).month==i):\n",
    "                temp.extend([1]) #月をonehotで追加\n",
    "                #time.sleep(0.1)\n",
    "            else:\n",
    "                temp.extend([0])\n",
    "                \n",
    "        temp.extend([datetime.datetime.fromisoformat(res['time'][:19]).day])  #日を追加\n",
    "        \n",
    "        for i in range(0,7):\n",
    "            \n",
    "            if(datetime.datetime.fromisoformat(res['time'][:19]).weekday==i):\n",
    "                temp.extend([1]) #曜日をonehotで追加\n",
    "                #time.sleep(0.00001)\n",
    "            else:\n",
    "                temp.extend([0])\n",
    "        \n",
    "        temp.extend([res['volume'],\n",
    "            res['mid']['o'],\n",
    "            res['mid']['h'],\n",
    "            res['mid']['l'],\n",
    "            res['mid']['c'],\n",
    "            ])\n",
    "        data.append(temp)\n",
    "    return data\n",
    "\n",
    "all_data = []\n",
    "# year, monthでループ\n",
    "#for year, month in year_months:\n",
    "\n",
    "NY = datetime.timedelta(hours=-13) + datetime.timedelta(seconds=-1)#レートは時差を考慮して取得\n",
    "\n",
    "# -13hしないと\"This time is future\"となることから、入力した時間はNY時間として認識される。\n",
    "\n",
    "\n",
    "bias = datetime.timedelta(days=-1)\n",
    "\n",
    "\n",
    "date_from = datetime.datetime.now() + NY + datetime.timedelta(minutes=-3000) + bias\n",
    "date_to =  datetime.datetime.now() + NY +bias\n",
    "\n",
    "print(\"入力はNY(-13h)で行う。これにより最新のレートが取得できる。\")\n",
    "print(\"ただし、indexに出力されるのはGMT(-9h)である。\")\n",
    "print(\"JPN: \"+str(datetime.datetime.now()))\n",
    "print(\"NY: \"+str(date_from)+\" \"+str(date_to))\n",
    "print(\"GMT(index): \"+str(date_from+datetime.timedelta(hours=4))+\" \"+str(date_to+datetime.timedelta(hours=4)))\n",
    "\n",
    "ret = getCandleDataFromOanda(\"USD_JPY\", api, date_from, date_to, \"M10\")\n",
    "twohours_data = oandaJsonToPythonList(ret)#取得したデータを格納\n",
    "\n",
    "\n",
    "\n",
    "all_data.extend(twohours_data)#データを追加\n",
    "\n",
    "#print(all_data)\n",
    "\n",
    "#ここからall_dataに追加すればよい\n",
    "\n",
    "\n",
    "# pandas DataFrameへ変換\n",
    "now_df = pd.DataFrame(all_data)\n",
    "now_df.columns = ['Datetime',\n",
    "              \"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\",\n",
    "              \"day\",\n",
    "              \"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\n",
    "              'Volume', 'Open', 'High', 'Low', 'Close']\n",
    "now_df = now_df.set_index('Datetime')\n",
    "\n",
    "#print(now_df)\n",
    "\n",
    "def adjust_now_data(df, num=1):\n",
    "    \n",
    "    df = df.astype(float)\n",
    "    \n",
    "    #以降全ての計算でレート終値を使う\n",
    "    close = np.array(df[\"Close\"])\n",
    "    \n",
    "    \n",
    "    #特徴量を入れるための空のdataframeを作成\n",
    "    df_feature = pd.DataFrame(columns=[ \n",
    "        \"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\n",
    "        \"July\",\"August\",\"September\",\"October\",\"November\",\"December\",\n",
    "        \"day\",\n",
    "        \"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\n",
    "        \"SMA_hour/current\",\n",
    "        \"SMA_2hour/current\",\n",
    "        \"RSI\",\n",
    "        \"MACD\",\n",
    "        \"BBANDS+2σ\",\n",
    "        \"BBANDS-2σ\",\n",
    "        \"10m_rate\",\n",
    "        \"30m_rate\",\n",
    "        \"60m_rate\",\n",
    "        \"120m_rate\"\n",
    "        ])\n",
    "\n",
    "\n",
    "    df_feature[\"January\"] = df[\"January\"]\n",
    "    df_feature[\"February\"] = df[\"February\"]\n",
    "    df_feature[\"March\"] = df[\"March\"]\n",
    "    df_feature[\"April\"] = df[\"April\"]\n",
    "    df_feature[\"May\"] = df[\"May\"]\n",
    "    df_feature[\"June\"] = df[\"June\"]\n",
    "    df_feature[\"July\"] = df[\"July\"]\n",
    "    df_feature[\"August\"] = df[\"August\"]\n",
    "    df_feature[\"September\"] = df[\"September\"]\n",
    "    df_feature[\"October\"] = df[\"October\"]\n",
    "    df_feature[\"November\"] = df[\"November\"]\n",
    "    df_feature[\"December\"] = df[\"December\"]\n",
    "    \n",
    "    #print(df_feature.isnull().any())\n",
    "    \n",
    "    #print(df_feature.isnull().any())\n",
    "    \n",
    "#     days=[\"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"]\n",
    "#     for i in days:\n",
    "#         df_feature[i] = df[i]\n",
    "\n",
    "    df_feature[\"Sunday\"] = df[\"Sunday\"]\n",
    "    df_feature[\"Monday\"] = df[\"Monday\"]\n",
    "    df_feature[\"Thuesday\"] = df[\"Thuesday\"]\n",
    "    df_feature[\"Wednesday\"] = df[\"Wednesday\"]\n",
    "    df_feature[\"Thursday\"] = df[\"Thursday\"]\n",
    "    df_feature[\"Friday\"] = df[\"Friday\"]\n",
    "    df_feature[\"Saturday\"] = df[\"Saturday\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_feature[\"day\"] = df[\"day\"]\n",
    "    df_feature[\"10m_rate\"] = df[\"Close\"].astype(float).pct_change()*100\n",
    "    df_feature[\"30m_rate\"] = df[\"Close\"].astype(float).pct_change(3)*100\n",
    "    df_feature[\"60m_rate\"] = df[\"Close\"].astype(float).pct_change(6)*100\n",
    "    df_feature[\"120m_rate\"] = df[\"Close\"].astype(float).pct_change(12)*100\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #以下、talibを用いてテクニカル指標（今回の学習で用いる特徴量）を算出しdf_feature入れる\n",
    "\n",
    "    #単純移動平均は、単純移動平均値とその日の終値の比を特徴量として用いる\n",
    "    df_feature[\"SMA_hour/current\"]= ta.SMA(close, timeperiod=6) / close\n",
    "    df_feature[\"SMA_2hour/current\"]= ta.SMA(close, timeperiod=12) / close\n",
    "\n",
    "    #RSI\n",
    "    df_feature[\"RSI\"] = ta.RSI(close, timeperiod=12)\n",
    "\n",
    "    #MACD\n",
    "    df_feature[\"MACD\"], _ , _= ta.MACD(close, fastperiod=3, slowperiod=18, signalperiod=9)\n",
    "\n",
    "    #ボリンジャーバンド \n",
    "    upper, middle, lower = ta.BBANDS(close, timeperiod=20, nbdevup=3, nbdevdn=3)\n",
    "    df_feature[\"BBANDS+2σ\"] = upper / close\n",
    "    df_feature[\"BBANDS-2σ\"] = lower / close\n",
    "\n",
    "    \n",
    "    \n",
    "    c=[0,0,0]\n",
    "    \n",
    "    def classify(x):\n",
    "        percent = 0.05\n",
    "\n",
    "        if x<-percent:\n",
    "            c[0]+=1\n",
    "            return 0\n",
    "        elif -percent<x<percent:\n",
    "            c[1]+=1\n",
    "            return 1\n",
    "        elif percent<x:\n",
    "            c[2]+=1\n",
    "            return 2\n",
    "\n",
    "    classified = pd.DataFrame(columns=[\"class\"])\n",
    "    classified[\"class\"] = df_feature[\"120m_rate\"].apply(lambda x: classify(x))\n",
    "\n",
    "    #classified = classified.shift(-1)\n",
    "    classified = classified.shift(-12)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     df_adjusted=df_feature[30:len(df_feature)-1]\n",
    "#     classified=classified[30:len(classified)-1]\n",
    "    \n",
    "    df_adjusted=df_feature.tail(num)\n",
    "    classified=classified.tail(num)\n",
    "    \n",
    "    print(c)\n",
    "    \n",
    "    #print(df_adjusted, classified)\n",
    "    \n",
    "    return df_adjusted, classified\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "def predict(now_df, filename = 'RF_01.sav'):\n",
    "    \n",
    "    data_num = 100\n",
    "    \n",
    "    X_now, y_now = adjust_now_data(now_df, data_num)\n",
    "\n",
    "    #print(X_now, y_now)\n",
    "\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    #result = loaded_model.score(X_now, y_now)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(loaded_model.predict(X_now)[:data_num-12], y_now[\"class\"].values[:data_num-12]))\n",
    "    \n",
    "    from sklearn.metrics import precision_score\n",
    "    print(precision_score(loaded_model.predict(X_now)[:data_num-12], y_now[\"class\"].values[:data_num-12], average=None))\n",
    "    \n",
    "    return loaded_model.predict(X_now)\n",
    "\n",
    "predict(now_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力はNY(-13h)で行う。これにより最新のレートが取得できる。\n",
      "JPN: 2020-10-08 20:00\n",
      "NY: FROM 2020-09-03 13:40:02.940956 TO 2020-10-08 07:00:02.940956\n",
      "Recent 50minutes rate\n",
      "Datetime\n",
      "2020-10-08 19:20    105.994\n",
      "2020-10-08 19:30    106.002\n",
      "2020-10-08 19:40    106.018\n",
      "2020-10-08 19:50    106.030\n",
      "2020-10-08 20:00    106.030\n",
      "Name: Close, dtype: object\n",
      "\n",
      "[down/up]\n",
      "[1716, 1834, 6]\n",
      "The following is the accuracy during 10days.\n",
      "accuracy_score: 0.5292887029288703\n",
      "precision_score: [0.40810811 0.65850144]\n",
      "[[302 438]\n",
      " [237 457]]\n",
      "next is UP\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from oandapyV20 import API\n",
    "from oandapyV20.exceptions import V20Error\n",
    "from oandapyV20.endpoints.pricing import PricingStream\n",
    "import oandapyV20.endpoints.orders as orders\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "from IPython.display import display\n",
    "import talib as ta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "#自分のアカウント、トークンをセット\n",
    "accountID = \"101-009-16415310-001\"\n",
    "access_token = '860c2d2dbbcd01b6d95939b6af6b5981-8664724ce0870220c55161d704137df6'\n",
    "\n",
    "api = API(access_token=access_token, environment=\"practice\")\n",
    "\n",
    "# year_months =[ [2016, 1], [2016, 2], [2016, 3], [2016, 4], [2016, 5], [2016, 6], [2016, 7], [2016, 8], [2016, 9], [2016, 10], [2016, 11], [2016, 12],\n",
    "#     [2017, 1], [2017, 2], [2017, 3], [2017, 4], [2017, 5], [2017, 6], [2017, 7], [2017, 8], [2017, 9], [2017, 10], [2017, 11], [2017, 12],\n",
    "#     [2018, 1], [2018, 2], [2018, 3], [2018, 4], [2018, 5], [2018, 6], [2018, 7], [2018, 8], [2018, 9], [2018, 10], [2018, 11], [2018, 12],[2019, 1], [2019, 2], [2019, 3], [2019, 4], [2019, 5], [2019, 6], [2019, 7]]\n",
    "\n",
    "## Oandaからcandleデータを取得する。 時差のため、現在のレート取得のため、-9h\n",
    "def getCandleDataFromOanda(instrument, api, date_from, date_to, granularity):\n",
    "    params = {\n",
    "        \"from\": date_from.isoformat(),\n",
    "        \"to\": date_to.isoformat(),\n",
    "        \"granularity\": granularity,\n",
    "    }\n",
    "    r = instruments.InstrumentsCandles(instrument=instrument, params=params)\n",
    "    return api.request(r)\n",
    "\n",
    "def oandaJsonToPythonList(JSONRes):\n",
    "    \n",
    "    #adjust = datetime.timedelta(hours=-4)\n",
    "    adjust = datetime.timedelta(hours=9) #GMT to JPN\n",
    "    \n",
    "    data = []\n",
    "    for res in JSONRes['candles']:\n",
    "        temp = [(datetime.datetime.fromisoformat(res['time'][:19]) + adjust).strftime('%Y-%m-%d %H:%M')] #indexとなる時間を追加\n",
    "        \n",
    "        temp.extend([datetime.datetime.fromisoformat(res['time'][:19]).hour]) #時間を追加\n",
    "        \n",
    "#         month = datetime.datetime.fromisoformat(res['time'][:19]).month\n",
    "        \n",
    "#         for i in range(1,13):\n",
    "           \n",
    "#             if(month==i):\n",
    "#                 temp.extend([1]) #月をonehotで追加\n",
    "#                 #time.sleep(0.1)\n",
    "#             else:\n",
    "#                 temp.extend([0])\n",
    "                \n",
    "        temp.extend([datetime.datetime.fromisoformat(res['time'][:19]).day])  #日を追加\n",
    "        \n",
    "#         weekday = datetime.datetime.fromisoformat(res['time'][:19]).weekday\n",
    "        \n",
    "#         for i in range(0,7):\n",
    "            \n",
    "#             if(weekday==i):\n",
    "#                 temp.extend([1]) #曜日をonehotで追加\n",
    "#                 #time.sleep(0.00001)\n",
    "#             else:\n",
    "#                 temp.extend([0])\n",
    "        \n",
    "        temp.extend([res['volume'],\n",
    "            res['mid']['o'],\n",
    "            res['mid']['h'],\n",
    "            res['mid']['l'],\n",
    "            res['mid']['c'],\n",
    "            ])\n",
    "        data.append(temp)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "all_data = []\n",
    "# year, monthでループ\n",
    "#for year, month in year_months:\n",
    "\n",
    "NY = datetime.timedelta(hours=-13) + datetime.timedelta(seconds=-1)#レートは時差を考慮して取得\n",
    "\n",
    "# -13hしないと\"This time is future\"となることから、入力した時間はNY時間として認識される。\n",
    "\n",
    "\n",
    "bias = datetime.timedelta(days=0)\n",
    "\n",
    "\n",
    "date_from = datetime.datetime.now() + NY + datetime.timedelta(minutes=-50000) + bias\n",
    "date_to =  datetime.datetime.now() + NY +bias\n",
    "\n",
    "print(\"入力はNY(-13h)で行う。これにより最新のレートが取得できる。\")\n",
    "print(\"JPN: \"+str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M')))\n",
    "print(\"NY: FROM \"+str(date_from)+\" TO \"+str(date_to))\n",
    "#print(\"GMT(index): \"+str(date_from+datetime.timedelta(hours=4))+\" \"+str(date_to+datetime.timedelta(hours=4)))\n",
    "\n",
    "ret = getCandleDataFromOanda(\"USD_JPY\", api, date_from, date_to, \"M10\")\n",
    "twohours_data = oandaJsonToPythonList(ret)#取得したデータを格納\n",
    "\n",
    "\n",
    "\n",
    "all_data.extend(twohours_data)#データを追加\n",
    "\n",
    "#print(all_data)\n",
    "\n",
    "#ここからall_dataに追加すればよい\n",
    "\n",
    "\n",
    "# pandas DataFrameへ変換\n",
    "now_df = pd.DataFrame(all_data)\n",
    "now_df.columns = ['Datetime',\"hour_range\",\n",
    "              #\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\",\n",
    "              \"day\",\n",
    "              #\"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\n",
    "              'Volume', 'Open', 'High', 'Low', 'Close']\n",
    "now_df = now_df.set_index('Datetime')\n",
    "\n",
    "#print(now_df)\n",
    "\n",
    "def adjust_now_data(df, num=1):\n",
    "    \n",
    "    df = df.astype(float)\n",
    "    \n",
    "    #以降全ての計算でレート終値を使う\n",
    "    close = np.array(df[\"Close\"])\n",
    "    \n",
    "    \n",
    "    #特徴量を入れるための空のdataframeを作成\n",
    "    df_feature = pd.DataFrame(columns=[ \n",
    "        \"Close\",\n",
    "        \"hour_range\",\n",
    "        #\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\n",
    "        #\"July\",\"August\",\"September\",\"October\",\"November\",\"December\",\n",
    "        \"day\",\n",
    "        #\"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\n",
    "        \"SMA_hour/current\",\n",
    "        \"SMA_2hour/current\",\n",
    "        \"RSI\",\n",
    "        \"MACD\",\n",
    "        \"BBANDS+2σ\",\n",
    "        \"BBANDS-2σ\",\n",
    "        ])\n",
    "\n",
    "    df_feature[\"Close\"] = df[\"Close\"]\n",
    "    df_feature[\"hour_range\"] = df[\"hour_range\"]\n",
    "    \n",
    "#     df_feature[\"January\"] = df[\"January\"]\n",
    "#     df_feature[\"February\"] = df[\"February\"]\n",
    "#     df_feature[\"March\"] = df[\"March\"]\n",
    "#     df_feature[\"April\"] = df[\"April\"]\n",
    "#     df_feature[\"May\"] = df[\"May\"]\n",
    "#     df_feature[\"June\"] = df[\"June\"]\n",
    "#     df_feature[\"July\"] = df[\"July\"]\n",
    "#     df_feature[\"August\"] = df[\"August\"]\n",
    "#     df_feature[\"September\"] = df[\"September\"]\n",
    "#     df_feature[\"October\"] = df[\"October\"]\n",
    "#     df_feature[\"November\"] = df[\"November\"]\n",
    "#     df_feature[\"December\"] = df[\"December\"]\n",
    "    \n",
    "    #print(df_feature.isnull().any())\n",
    "    \n",
    "    #print(df_feature.isnull().any())\n",
    "    \n",
    "#     days=[\"Sunday\",\"Monday\",\"Thuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"]\n",
    "#     for i in days:\n",
    "#         df_feature[i] = df[i]\n",
    "\n",
    "#     df_feature[\"Sunday\"] = df[\"Sunday\"]\n",
    "#     df_feature[\"Monday\"] = df[\"Monday\"]\n",
    "#     df_feature[\"Thuesday\"] = df[\"Thuesday\"]\n",
    "#     df_feature[\"Wednesday\"] = df[\"Wednesday\"]\n",
    "#     df_feature[\"Thursday\"] = df[\"Thursday\"]\n",
    "#     df_feature[\"Friday\"] = df[\"Friday\"]\n",
    "#     df_feature[\"Saturday\"] = df[\"Saturday\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_feature[\"day\"] = df[\"day\"]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #以下、talibを用いてテクニカル指標（今回の学習で用いる特徴量）を算出しdf_feature入れる\n",
    "\n",
    "    #単純移動平均は、単純移動平均値とその日の終値の比を特徴量として用いる\n",
    "    df_feature[\"SMA_hour/current\"]= ta.SMA(close, timeperiod=6) / close\n",
    "    df_feature[\"SMA_2hour/current\"]= ta.SMA(close, timeperiod=12) / close\n",
    "\n",
    "    #RSI\n",
    "    df_feature[\"RSI\"] = ta.RSI(close, timeperiod=12)\n",
    "\n",
    "    #MACD\n",
    "    df_feature[\"MACD\"], _ , _= ta.MACD(close, fastperiod=3, slowperiod=18, signalperiod=9)\n",
    "\n",
    "    #ボリンジャーバンド \n",
    "    upper, middle, lower = ta.BBANDS(close, timeperiod=20, nbdevup=3, nbdevdn=3)\n",
    "    df_feature[\"BBANDS+2σ\"] = upper / close\n",
    "    df_feature[\"BBANDS-2σ\"] = lower / close\n",
    "\n",
    "    \n",
    "    c=[0,0,0]\n",
    "    \n",
    "    \n",
    "    def classify(x):\n",
    "\n",
    "        if x<0:\n",
    "            c[0]+=1\n",
    "            return 0\n",
    "        elif 0<=x:\n",
    "            c[1]+=1\n",
    "            return 1\n",
    "        else:\n",
    "            c[2] +=1\n",
    "\n",
    "    legs = 60\n",
    "    \n",
    "    classified = pd.DataFrame(columns=[\"class\"])\n",
    "    classified[\"class\"] = (df[\"Close\"].pct_change(int(legs/10))*100).apply(lambda x: classify(x))\n",
    "\n",
    "    #classified = classified.shift(-1)\n",
    "    classified = classified.shift(-int(legs/10))\n",
    "    \n",
    "    \n",
    "    #df_adjusted=df_feature[30:len(df_feature)-2]\n",
    "    #classified=classified[30:len(classified)-2]\n",
    "    df_adjusted=df_feature[30:len(df_feature)-int(legs/10)]\n",
    "    classified=classified[30:len(classified)-int(legs/10)]\n",
    "    \n",
    "    \n",
    "    print(\"[down/up]\")\n",
    "    print(c)\n",
    "    \n",
    "    \n",
    "    #print(df_adjusted, classified)\n",
    "    \n",
    "    return df_adjusted, classified\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "def predict(now_df, filename = 'RF_01.sav'):\n",
    "    \n",
    "    day = 10\n",
    "    \n",
    "    data_num = 6*24*day #60分×24時間×days 間での予測精度を表示\n",
    "    \n",
    "    \n",
    "    print(\"Recent 50minutes rate\")\n",
    "    print(now_df[\"Close\"].tail())\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    X_now, y_now = adjust_now_data(now_df)\n",
    "\n",
    "    #print(X_now, y_now)\n",
    "\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    #result = loaded_model.score(X_now, y_now)\n",
    "\n",
    "    print(\"The following is the accuracy during \"+str(day)+\"days.\")\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    result = loaded_model.predict(X_now)\n",
    "    \n",
    "#     color = []\n",
    "#     for x in range(0,data_num-6):\n",
    "#         if y_now[\"class\"].values[x] == result[x]:\n",
    "#             color.extend([\"#aaaaFF\"])\n",
    "#         else:\n",
    "#             color.extend([\"#FFaaaa\"])\n",
    "\n",
    "#     plt.figure(figsize=(50,5))\n",
    "    \n",
    "#     for x in range(0,data_num-6):\n",
    "#         if y_now[\"class\"].values[x] == result[x]:\n",
    "#             color = 'blue'\n",
    "#         else:\n",
    "#             color = 'red'\n",
    "            \n",
    "#         #plt.plot(X_now.index.values[x], X_now[\"Close\"].values[x], color=color)\n",
    "#         plt.scatter(X_now.index.values[x], X_now[\"Close\"].values[x], color=color)\n",
    "    \n",
    "#     plt.xticks(rotation=90)\n",
    "    \n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "#     print(color)\n",
    "#     print(X_now[\"Close\"].values[:data_num-6])\n",
    "#     print(X_now.index.values[:data_num-6])\n",
    "#     print(y_now[\"class\"].values)\n",
    "#     print(result)\n",
    "    \n",
    "    print(\"accuracy_score: \", end=\"\")\n",
    "    print(accuracy_score(result[:data_num-6], y_now[\"class\"].values[:data_num-6]))\n",
    "    \n",
    "    from sklearn.metrics import precision_score\n",
    "    print(\"precision_score: \", end=\"\")\n",
    "    print(precision_score(result[:data_num-6], y_now[\"class\"].values[:data_num-6], average=None))\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_now[\"class\"].values[:data_num-6], result[:data_num-6]))\n",
    "    \n",
    "    return loaded_model.predict(X_now)\n",
    "\n",
    "result = predict(now_df)\n",
    "\n",
    "\n",
    "\n",
    "if result[-1] == 1:\n",
    "    next_rate = \"UP\"\n",
    "elif result[-1] == 0:\n",
    "    next_rate = \"DOWN\"\n",
    "print(\"next is \", end=\"\")   \n",
    "print(next_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
