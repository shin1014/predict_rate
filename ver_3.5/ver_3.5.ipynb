{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 02:53:32.480086 2020-12-01 22:53:32.480086\n",
      "\"USD_JPY_2020-11-11_2020-12-02_30000.csv\", 2020-11-11 02:53:32.808189 2020-12-01 22:53:32.808189\n",
      "\"EUR_JPY_2020-11-11_2020-12-02_30000.csv\", 2020-11-11 02:53:33.089421 2020-12-01 22:53:33.089421\n",
      "\"AUD_JPY_2020-11-11_2020-12-02_30000.csv\", 2020-11-11 02:53:33.389482 2020-12-01 22:53:33.389482\n",
      "\"GBP_JPY_2020-11-11_2020-12-02_30000.csv\", 2020-11-11 02:53:33.686379 2020-12-01 22:53:33.686379\n",
      "\"NZD_JPY_2020-11-11_2020-12-02_30000.csv\", 2020-11-11 02:53:33.998858 2020-12-01 22:53:33.998858\n",
      "\"CAD_JPY_2020-11-11_2020-12-02_30000.csv\", 2020-11-11 02:53:34.280137 2020-12-01 22:53:34.280137\n",
      "\"CHF_JPY_2020-11-11_2020-12-02_30000.csv\", USD_JPY_2020-11-11_2020-12-02_30000.csv\n",
      "Train Data\n",
      " LOW/HIGH\n",
      "[0, 0]\n",
      "2020-12-01 22:53:34.576993 2020-12-11 22:53:34.576993\n",
      "money: USD_JPY\n",
      "NOW Data from14400minutes ago\n",
      " LOW/MID/HIGH\n",
      "[0, 0]\n",
      "learning data\n",
      "['2020-11-11 19:00'] to ['2020-12-02 12:45']\n",
      "\n",
      "test data\n",
      "['2020-12-02 15:00'] to ['2020-12-12 06:45']\n",
      "\n",
      "Random Forest\n",
      "|   iter    |  target   | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5215  \u001b[0m | \u001b[0m 0.1166  \u001b[0m | \u001b[0m 5.074   \u001b[0m | \u001b[0m 156.3   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5032  \u001b[0m | \u001b[0m 0.424   \u001b[0m | \u001b[0m 12.49   \u001b[0m | \u001b[0m 190.4   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5074  \u001b[0m | \u001b[0m 0.5029  \u001b[0m | \u001b[0m 21.82   \u001b[0m | \u001b[0m 74.17   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5138  \u001b[0m | \u001b[0m 0.9599  \u001b[0m | \u001b[0m 18.81   \u001b[0m | \u001b[0m 83.24   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5109  \u001b[0m | \u001b[0m 0.515   \u001b[0m | \u001b[0m 15.13   \u001b[0m | \u001b[0m 89.93   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5145  \u001b[0m | \u001b[0m 0.365   \u001b[0m | \u001b[0m 17.0    \u001b[0m | \u001b[0m 90.89   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5124  \u001b[0m | \u001b[0m 0.458   \u001b[0m | \u001b[0m 4.161   \u001b[0m | \u001b[0m 159.7   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5124  \u001b[0m | \u001b[0m 0.9377  \u001b[0m | \u001b[0m 4.669   \u001b[0m | \u001b[0m 154.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5138  \u001b[0m | \u001b[0m 0.3645  \u001b[0m | \u001b[0m 4.599   \u001b[0m | \u001b[0m 156.3   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5215  \u001b[0m | \u001b[0m 0.1971  \u001b[0m | \u001b[0m 5.259   \u001b[0m | \u001b[0m 156.4   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5145  \u001b[0m | \u001b[0m 0.3793  \u001b[0m | \u001b[0m 5.281   \u001b[0m | \u001b[0m 155.9   \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.523   \u001b[0m | \u001b[95m 0.1496  \u001b[0m | \u001b[95m 5.571   \u001b[0m | \u001b[95m 157.9   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5201  \u001b[0m | \u001b[0m 0.5723  \u001b[0m | \u001b[0m 5.647   \u001b[0m | \u001b[0m 157.3   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5201  \u001b[0m | \u001b[0m 0.3038  \u001b[0m | \u001b[0m 4.582   \u001b[0m | \u001b[0m 157.9   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.506   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 6.449   \u001b[0m | \u001b[0m 157.9   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5145  \u001b[0m | \u001b[0m 0.4487  \u001b[0m | \u001b[0m 4.988   \u001b[0m | \u001b[0m 157.5   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.518   \u001b[0m | \u001b[0m 0.7779  \u001b[0m | \u001b[0m 5.423   \u001b[0m | \u001b[0m 158.1   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5166  \u001b[0m | \u001b[0m 0.9667  \u001b[0m | \u001b[0m 6.155   \u001b[0m | \u001b[0m 157.2   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.501   \u001b[0m | \u001b[0m 0.8604  \u001b[0m | \u001b[0m 17.78   \u001b[0m | \u001b[0m 172.0   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5208  \u001b[0m | \u001b[0m 0.2717  \u001b[0m | \u001b[0m 3.897   \u001b[0m | \u001b[0m 158.3   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5215  \u001b[0m | \u001b[0m 0.153   \u001b[0m | \u001b[0m 5.308   \u001b[0m | \u001b[0m 156.6   \u001b[0m |\n",
      "| \u001b[95m 22      \u001b[0m | \u001b[95m 0.5251  \u001b[0m | \u001b[95m 0.5888  \u001b[0m | \u001b[95m 2.835   \u001b[0m | \u001b[95m 158.0   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.5173  \u001b[0m | \u001b[0m 0.8164  \u001b[0m | \u001b[0m 3.348   \u001b[0m | \u001b[0m 157.7   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.4982  \u001b[0m | \u001b[0m 0.1626  \u001b[0m | \u001b[0m 2.557   \u001b[0m | \u001b[0m 158.5   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.5152  \u001b[0m | \u001b[0m 0.7362  \u001b[0m | \u001b[0m 3.037   \u001b[0m | \u001b[0m 158.3   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.5244  \u001b[0m | \u001b[0m 0.4793  \u001b[0m | \u001b[0m 2.979   \u001b[0m | \u001b[0m 157.7   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.5237  \u001b[0m | \u001b[0m 0.5222  \u001b[0m | \u001b[0m 2.576   \u001b[0m | \u001b[0m 157.8   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.5173  \u001b[0m | \u001b[0m 0.5929  \u001b[0m | \u001b[0m 4.626   \u001b[0m | \u001b[0m 158.3   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5081  \u001b[0m | \u001b[0m 0.937   \u001b[0m | \u001b[0m 2.718   \u001b[0m | \u001b[0m 157.8   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.5244  \u001b[0m | \u001b[0m 0.405   \u001b[0m | \u001b[0m 2.82    \u001b[0m | \u001b[0m 157.5   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.5145  \u001b[0m | \u001b[0m 0.4515  \u001b[0m | \u001b[0m 4.026   \u001b[0m | \u001b[0m 157.8   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.5187  \u001b[0m | \u001b[0m 0.1586  \u001b[0m | \u001b[0m 3.282   \u001b[0m | \u001b[0m 157.6   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.4996  \u001b[0m | \u001b[0m 0.2107  \u001b[0m | \u001b[0m 2.264   \u001b[0m | \u001b[0m 156.7   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.5109  \u001b[0m | \u001b[0m 0.8426  \u001b[0m | \u001b[0m 7.107   \u001b[0m | \u001b[0m 107.3   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.5208  \u001b[0m | \u001b[0m 0.2535  \u001b[0m | \u001b[0m 3.977   \u001b[0m | \u001b[0m 158.9   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.5187  \u001b[0m | \u001b[0m 0.3252  \u001b[0m | \u001b[0m 3.04    \u001b[0m | \u001b[0m 158.0   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.523   \u001b[0m | \u001b[0m 0.1408  \u001b[0m | \u001b[0m 5.635   \u001b[0m | \u001b[0m 157.2   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.5215  \u001b[0m | \u001b[0m 0.1105  \u001b[0m | \u001b[0m 5.852   \u001b[0m | \u001b[0m 156.7   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.5138  \u001b[0m | \u001b[0m 0.4931  \u001b[0m | \u001b[0m 5.764   \u001b[0m | \u001b[0m 156.6   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.5215  \u001b[0m | \u001b[0m 0.1907  \u001b[0m | \u001b[0m 5.912   \u001b[0m | \u001b[0m 156.7   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.5187  \u001b[0m | \u001b[0m 0.5231  \u001b[0m | \u001b[0m 20.78   \u001b[0m | \u001b[0m 35.2    \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.5222  \u001b[0m | \u001b[0m 0.7799  \u001b[0m | \u001b[0m 11.59   \u001b[0m | \u001b[0m 123.0   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.5003  \u001b[0m | \u001b[0m 0.8732  \u001b[0m | \u001b[0m 20.39   \u001b[0m | \u001b[0m 140.3   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.5053  \u001b[0m | \u001b[0m 0.8463  \u001b[0m | \u001b[0m 11.62   \u001b[0m | \u001b[0m 123.3   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.5208  \u001b[0m | \u001b[0m 0.4596  \u001b[0m | \u001b[0m 11.7    \u001b[0m | \u001b[0m 122.7   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.5131  \u001b[0m | \u001b[0m 0.9147  \u001b[0m | \u001b[0m 3.809   \u001b[0m | \u001b[0m 158.8   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.5003  \u001b[0m | \u001b[0m 0.1288  \u001b[0m | \u001b[0m 2.728   \u001b[0m | \u001b[0m 157.7   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.5145  \u001b[0m | \u001b[0m 0.3406  \u001b[0m | \u001b[0m 17.89   \u001b[0m | \u001b[0m 90.2    \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.523   \u001b[0m | \u001b[0m 0.1569  \u001b[0m | \u001b[0m 5.978   \u001b[0m | \u001b[0m 157.2   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.5244  \u001b[0m | \u001b[0m 0.4291  \u001b[0m | \u001b[0m 2.928   \u001b[0m | \u001b[0m 157.3   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.5095  \u001b[0m | \u001b[0m 0.9846  \u001b[0m | \u001b[0m 8.214   \u001b[0m | \u001b[0m 152.5   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.5109  \u001b[0m | \u001b[0m 0.6167  \u001b[0m | \u001b[0m 3.008   \u001b[0m | \u001b[0m 157.6   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.5053  \u001b[0m | \u001b[0m 0.933   \u001b[0m | \u001b[0m 23.46   \u001b[0m | \u001b[0m 35.38   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.5102  \u001b[0m | \u001b[0m 0.4325  \u001b[0m | \u001b[0m 7.559   \u001b[0m | \u001b[0m 185.8   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.5123  \u001b[0m | \u001b[0m 0.473   \u001b[0m | \u001b[0m 5.602   \u001b[0m | \u001b[0m 157.6   \u001b[0m |\n",
      "=============================================================\n",
      "{'target': 0.5250698717718042, 'params': {'max_features': 0.5887519993107497, 'min_samples_split': 2.83509315761536, 'n_estimators': 158.0279748877145}}\n",
      "[0.17515011 0.16480401 0.16559714 0.16433328 0.1655549  0.16456055]\n",
      "accuracy_score: 0.5238095238095238\n",
      "confusion_matrix: \n",
      "[[207 161]\n",
      " [189 178]]\n",
      "precision_score: [0.52272727 0.52507375]\n",
      "735hours trade\n",
      "profit: -22.75\n",
      "\n",
      "CLEAR: USD_JPY_Random Forest_30000_0.5238095238095238.sav\n",
      "[0.5238095238095238]\n",
      "EUR_JPY_2020-11-11_2020-12-02_30000.csv\n",
      "Train Data\n",
      " LOW/HIGH\n",
      "[0, 0]\n",
      "2020-12-01 22:54:03.126685 2020-12-11 22:54:03.126685\n",
      "money: EUR_JPY\n",
      "NOW Data from14400minutes ago\n",
      " LOW/MID/HIGH\n",
      "[0, 0]\n",
      "learning data\n",
      "['2020-11-11 19:00'] to ['2020-12-02 12:45']\n",
      "\n",
      "test data\n",
      "['2020-12-02 15:00'] to ['2020-12-12 06:45']\n",
      "\n",
      "Random Forest\n",
      "|   iter    |  target   | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.4855  \u001b[0m | \u001b[0m 0.5005  \u001b[0m | \u001b[0m 7.812   \u001b[0m | \u001b[0m 92.51   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.4792  \u001b[0m | \u001b[0m 0.2356  \u001b[0m | \u001b[0m 7.848   \u001b[0m | \u001b[0m 82.27   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.494   \u001b[0m | \u001b[95m 0.991   \u001b[0m | \u001b[95m 12.3    \u001b[0m | \u001b[95m 196.3   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.4862  \u001b[0m | \u001b[0m 0.9044  \u001b[0m | \u001b[0m 11.08   \u001b[0m | \u001b[0m 107.4   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.4947  \u001b[0m | \u001b[95m 0.6019  \u001b[0m | \u001b[95m 6.077   \u001b[0m | \u001b[95m 166.9   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.4834  \u001b[0m | \u001b[0m 0.3164  \u001b[0m | \u001b[0m 7.132   \u001b[0m | \u001b[0m 166.5   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.4841  \u001b[0m | \u001b[0m 0.2749  \u001b[0m | \u001b[0m 5.063   \u001b[0m | \u001b[0m 122.8   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.4968  \u001b[0m | \u001b[95m 0.3933  \u001b[0m | \u001b[95m 17.45   \u001b[0m | \u001b[95m 92.45   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.4827  \u001b[0m | \u001b[0m 0.1232  \u001b[0m | \u001b[0m 2.434   \u001b[0m | \u001b[0m 182.9   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.4855  \u001b[0m | \u001b[0m 0.4505  \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 56.27   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.4862  \u001b[0m | \u001b[0m 0.2554  \u001b[0m | \u001b[0m 24.13   \u001b[0m | \u001b[0m 199.6   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.4968  \u001b[0m | \u001b[0m 0.446   \u001b[0m | \u001b[0m 17.46   \u001b[0m | \u001b[0m 92.49   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.4799  \u001b[0m | \u001b[0m 0.6119  \u001b[0m | \u001b[0m 5.238   \u001b[0m | \u001b[0m 167.1   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.4961  \u001b[0m | \u001b[0m 0.6967  \u001b[0m | \u001b[0m 6.346   \u001b[0m | \u001b[0m 167.2   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.489   \u001b[0m | \u001b[0m 0.2603  \u001b[0m | \u001b[0m 17.88   \u001b[0m | \u001b[0m 92.83   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.4968  \u001b[0m | \u001b[0m 0.6732  \u001b[0m | \u001b[0m 17.08   \u001b[0m | \u001b[0m 92.23   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.4919  \u001b[0m | \u001b[0m 0.7041  \u001b[0m | \u001b[0m 17.46   \u001b[0m | \u001b[0m 91.74   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.494   \u001b[0m | \u001b[0m 0.844   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 195.4   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.4926  \u001b[0m | \u001b[0m 0.2426  \u001b[0m | \u001b[0m 16.43   \u001b[0m | \u001b[0m 92.74   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.4855  \u001b[0m | \u001b[0m 0.9398  \u001b[0m | \u001b[0m 11.36   \u001b[0m | \u001b[0m 196.0   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.4905  \u001b[0m | \u001b[0m 0.9277  \u001b[0m | \u001b[0m 13.03   \u001b[0m | \u001b[0m 195.5   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.4912  \u001b[0m | \u001b[0m 0.1724  \u001b[0m | \u001b[0m 16.63   \u001b[0m | \u001b[0m 91.96   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.4756  \u001b[0m | \u001b[0m 0.877   \u001b[0m | \u001b[0m 16.87   \u001b[0m | \u001b[0m 92.75   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.4792  \u001b[0m | \u001b[0m 0.4937  \u001b[0m | \u001b[0m 12.47   \u001b[0m | \u001b[0m 195.6   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.4968  \u001b[0m | \u001b[0m 0.6713  \u001b[0m | \u001b[0m 17.52   \u001b[0m | \u001b[0m 92.13   \u001b[0m |\n",
      "| \u001b[95m 26      \u001b[0m | \u001b[95m 0.4982  \u001b[0m | \u001b[95m 0.4445  \u001b[0m | \u001b[95m 17.19   \u001b[0m | \u001b[95m 91.93   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.4961  \u001b[0m | \u001b[0m 0.7338  \u001b[0m | \u001b[0m 12.13   \u001b[0m | \u001b[0m 202.9   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.489   \u001b[0m | \u001b[0m 0.1729  \u001b[0m | \u001b[0m 17.2    \u001b[0m | \u001b[0m 92.23   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.4968  \u001b[0m | \u001b[0m 0.3953  \u001b[0m | \u001b[0m 6.339   \u001b[0m | \u001b[0m 167.1   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.494   \u001b[0m | \u001b[0m 0.999   \u001b[0m | \u001b[0m 12.2    \u001b[0m | \u001b[0m 195.0   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.4876  \u001b[0m | \u001b[0m 0.2617  \u001b[0m | \u001b[0m 22.55   \u001b[0m | \u001b[0m 179.3   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.4926  \u001b[0m | \u001b[0m 0.6383  \u001b[0m | \u001b[0m 12.12   \u001b[0m | \u001b[0m 203.3   \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "from oandapyV20 import API\n",
    "from oandapyV20.exceptions import V20Error\n",
    "from oandapyV20.endpoints.pricing import PricingStream\n",
    "import oandapyV20.endpoints.orders as orders\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import time\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "import pickle\n",
    "import math\n",
    "import glob\n",
    "import talib as ta\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import schedule\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from pprint import pprint\n",
    "\n",
    "#自分のアカウント、トークンをセット\n",
    "accountID = \"101-009-16415310-001\"\n",
    "access_token = '860c2d2dbbcd01b6d95939b6af6b5981-8664724ce0870220c55161d704137df6'\n",
    "\n",
    "api = API(access_token=access_token, environment=\"practice\")\n",
    "        \n",
    "# Oandaからcandleデータを取得する。\n",
    "def getCandleDataFromOanda(instrument, api, date_from, date_to, granularity):\n",
    "    params = {\n",
    "        \"from\": date_from.isoformat(),\n",
    "        \"to\": date_to.isoformat(),\n",
    "        \"granularity\": granularity,\n",
    "    }\n",
    "    r = instruments.InstrumentsCandles(instrument=instrument, params=params)\n",
    "    return api.request(r)\n",
    "\n",
    "def oandaJsonToPythonList(JSONRes):\n",
    "    \n",
    "    data = []\n",
    "    for res in JSONRes['candles']:\n",
    "        temp = [((datetime.datetime.fromisoformat(res['time'][:19]))+datetime.timedelta(hours=+9)).strftime('%Y-%m-%d %H:%M')]#indexとなる時間を追加\n",
    "        temp.extend([res['volume'],\n",
    "            res['mid']['o'],\n",
    "            res['mid']['h'],\n",
    "            res['mid']['l'],\n",
    "            res['mid']['c'],\n",
    "            ])\n",
    "        data.append(temp)\n",
    "    return data\n",
    "\n",
    "def logarism(x):\n",
    "    x = abs(x)\n",
    "    return math.log(x)\n",
    "\n",
    "\n",
    "def get_now_data(time, period_minutes, money, foot, back_days = 0):\n",
    "    \n",
    "    all_data = []\n",
    "    #time = time.replace(hour=7, minute=0, second=0, microsecond=0)\n",
    "    #入力された日の当日の7時\n",
    "    \n",
    "    global PAST\n",
    "    past = datetime.timedelta(hours=-PAST)\n",
    "    \n",
    "    NY = datetime.timedelta(hours=-14)\n",
    "    back = datetime.timedelta(days=-back_days)\n",
    "        \n",
    "    date_to = time + NY + datetime.timedelta(seconds=-1) + back + past\n",
    "\n",
    "    date_from = date_to + datetime.timedelta(minutes=-period_minutes)\n",
    "    \n",
    "    print(date_from, date_to)\n",
    "    \n",
    "    ret = getCandleDataFromOanda(money, api, date_from, date_to, foot)\n",
    "    month_data = oandaJsonToPythonList(ret)#取得したデータを格納\n",
    "\n",
    "    all_data.extend(month_data)#データを追加\n",
    "\n",
    "    # pandas DataFrameへ変換\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    df.columns = ['Datetime','Volume', 'Open', 'High', 'Low', 'Close']\n",
    "    \n",
    "    df['Volume'] = df['Volume'].astype('double')\n",
    "    df['Open'] = df['Open'].astype('double')\n",
    "    df['Close'] = df['Close'].astype('double')\n",
    "    \n",
    "    \n",
    "    close = np.array(df[\"Close\"]).astype(float)\n",
    "    #以下、talibを用いてテクニカル指標（今回の学習で用いる特徴量）を算出しdf_feature入れる\n",
    "    #単純移動平均は、単純移動平均値とその日の終値の比を特徴量として用いる\n",
    "    df[\"SMA5\"]= ta.SMA(close, timeperiod=5) / close\n",
    "    df[\"SMA10\"]= ta.SMA(close, timeperiod=10) / close\n",
    "    #df[\"RSI\"] = ta.RSI(close, timeperiod=9) / close\n",
    "    #ボリンジャーバンド \n",
    "    upper, middle, lower = ta.BBANDS(close, timeperiod=10, nbdevup=2, nbdevdn=2)\n",
    "    df[\"BBANDS+σ\"] = upper / close\n",
    "    df[\"BBANDS-σ\"] = lower / close\n",
    "    \n",
    "    #df['Rate']=(df['Close']-df['Open'])/df['Open']\n",
    "    \n",
    "    #df['Open'] = df['Open'].apply(lambda x: logarism(x))\n",
    "    #df['Close'] = df['Close'].apply(lambda x: logarism(x))\n",
    "    \n",
    "    df['Rate']=(df['Close'].astype('double')-df['Open'].astype('double'))/df['Open'].astype('double')\n",
    "    \n",
    "    count = [0,0]\n",
    "    df['class'] = (df[\"Rate\"]).apply(lambda x: classify_two(x, count))\n",
    "    \n",
    "    df['Rate'] = df['Rate']\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    df = df.drop('Open', axis=1)\n",
    "    df = df.drop('High', axis=1)\n",
    "    df = df.drop('Low', axis=1)\n",
    "    df = df.drop('Close', axis=1)\n",
    "#     df = df.drop('Volume', axis=1)\n",
    "#     df = df.drop('Rate', axis=1)\n",
    "    \n",
    "#     df = df.drop('SMA5', axis=1)\n",
    "#     df = df.drop('SMA10', axis=1)\n",
    "#     df = df.drop('RSI', axis=1)\n",
    "#     df = df.drop('BBANDS+σ', axis=1)\n",
    "#     df = df.drop('BBANDS-σ', axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df = df.set_index('Datetime')\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def get_csv(back_days, minutes, money):\n",
    "    \n",
    "    time = datetime.datetime.now() \n",
    "    \n",
    "    df = get_now_data(time, period_minutes=minutes, money=money, foot = FOOT , back_days=back_days)\n",
    "    date_to = (time+datetime.timedelta(days=-back_days)+datetime.timedelta(seconds=-1)).strftime(\"%Y-%m-%d\")\n",
    "    date_from = (time + datetime.timedelta(minutes=-minutes)+datetime.timedelta(days=-back_days)).strftime(\"%Y-%m-%d\")\n",
    "    df.to_csv(\"csv/\"+str(money)+\"_\"+ date_from + \"_\" + date_to +\"_\"+str(minutes)+'.csv', mode = 'w')\n",
    "    print('\"'+str(money)+\"_\"+ date_from + \"_\" + date_to +\"_\"+str(minutes)+'.csv', end='\", ')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_moneys_csv(back_days, minutes, moneylist):\n",
    "    csvlist = []\n",
    "    \n",
    "    time = datetime.datetime.now()\n",
    "    date_to = (time+datetime.timedelta(days=-back_days)+datetime.timedelta(seconds=-1)).strftime(\"%Y-%m-%d\")\n",
    "    date_from = (time + datetime.timedelta(minutes=-minutes)+datetime.timedelta(days=-back_days)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    for i in range (len(moneylist)):\n",
    "        get_csv(back_days, minutes, money=moneylist[i])\n",
    "        csvlist.extend([str(moneylist[i])+\"_\"+ date_from + \"_\" + date_to +\"_\"+str(minutes)+'.csv'])\n",
    "    \n",
    "    return csvlist\n",
    "        \n",
    "def classify_two(x, c):\n",
    "        if x<0:\n",
    "            c[0]+=1\n",
    "            return -1\n",
    "        elif 0<=x:\n",
    "            c[1]+=1\n",
    "            return 1\n",
    "        \n",
    "\n",
    "def predict(dataname, moneyname, test_minutes, back_day, datanum):\n",
    "\n",
    "    df = pd.read_csv(\"csv/\"+dataname, index_col='Datetime')\n",
    "    \n",
    "    count = [0,0]\n",
    "    #df['class'] = (df[\"Rate\"]).apply(lambda x: classify(x, count, 0.001))\n",
    "    df['class'] = df['class'].shift(-1)\n",
    "    print(\"Train Data\")\n",
    "    print(\" LOW/HIGH\")\n",
    "    print(count)\n",
    "    \n",
    "    X = df.drop('class', axis=1)\n",
    "    \n",
    "    \n",
    "    y = df['class']\n",
    "    X = X.drop(X.index[len(X)-1])\n",
    "    y = y.dropna()\n",
    "    \n",
    "\n",
    "    df_now = get_now_data(datetime.datetime.now(), period_minutes=test_minutes, money=moneyname, foot = FOOT, back_days = back_day)\n",
    "    print(\"money: \"+moneyname)\n",
    "    \n",
    "    count = [0,0]\n",
    "    #df['class'] = (df[\"Rate\"]).apply(lambda x: classify(x, count, 0.001))\n",
    "    #df_now['class'] = (df_now[\"Rate\"]).apply(lambda x: classify_two(x, count))\n",
    "    df_now['class'] = df_now['class'].shift(-1)\n",
    "    print(\"NOW Data from\" +str(test_minutes)+ \"minutes ago\")\n",
    "    print(\" LOW/MID/HIGH\")\n",
    "    print(count)\n",
    "    \n",
    "    print(\"learning data\")\n",
    "    print(df.head(1).index.values, end=' to ')\n",
    "    print(df.tail(1).index.values)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"test data\")\n",
    "    print(df_now.head(1).index.values,end=' to ')\n",
    "    print(df_now.tail(1).index.values)\n",
    "    print(\"\")\n",
    "    X_now = df_now.drop('class', axis=1)\n",
    "    \n",
    "    X_next = X_now.tail(1) #最終予測に利用\n",
    "    y_now = df_now['class']\n",
    "    X_now = X_now.drop(X_now.index[len(X_now)-1])\n",
    "    y_now = y_now.dropna()\n",
    "    \n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    X_test = X_now\n",
    "    y_test = y_now\n",
    "    \n",
    "    \n",
    "    names = [\n",
    "#         \"Nearest Neighbors\",\n",
    "#         \"Linear SVM\",\n",
    "#         \"RBF SVM\",\n",
    "#         \"Decision Tree\",\n",
    "        \"Random Forest\",\n",
    "#         \"AdaBoost\",\n",
    "#         \"Naive Bayes\",\n",
    "#         \"Linear Discriminant Analysis\",\n",
    "#         \"Quadratic Discriminant Analysis\"\n",
    "    ]\n",
    "    classifiers = [\n",
    "#     KNeighborsClassifier(3),\n",
    "#     SVC(kernel=\"linear\", C=0.025),\n",
    "#     SVC(gamma=2, C=1),\n",
    "#     DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(),#max_depth=10, n_estimators=10, max_features=1\n",
    "#     AdaBoostClassifier(),\n",
    "#     GaussianNB(),\n",
    "#     LinearDiscriminantAnalysis(),\n",
    "#     QuadraticDiscriminantAnalysis()\n",
    "    ]\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    next_class = []\n",
    "    profit = []\n",
    "    \n",
    "    clearlist = []\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        print(name)\n",
    "        \n",
    "        def randomforest_cv(n_estimators, min_samples_split, max_features):\n",
    "            val = cross_val_score(\n",
    "                RandomForestClassifier(\n",
    "                    n_estimators=int(n_estimators),\n",
    "                    min_samples_split=int(min_samples_split),\n",
    "                    max_features=max_features,\n",
    "                    random_state=0,\n",
    "                ),\n",
    "                X_train, y_train,\n",
    "                scoring = 'accuracy',\n",
    "                cv = 3, # 3-fold\n",
    "                n_jobs = -1 # use all CPUs\n",
    "            ).mean()\n",
    "            return val\n",
    "\n",
    "        randomforest_cv_bo = BayesianOptimization(\n",
    "            randomforest_cv,\n",
    "            {'n_estimators': (10, 250),\n",
    "            'min_samples_split': (2, 25),\n",
    "            'max_features': (0.1, 0.999),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        gp_params = {\"alpha\": 1e-5}\n",
    "        randomforest_cv_bo.maximize(n_iter=50, **gp_params)\n",
    "        print(randomforest_cv_bo.max)\n",
    "    \n",
    "        \n",
    "        clf = RandomForestClassifier(\n",
    "                    n_estimators=int(randomforest_cv_bo.max['params']['n_estimators']),\n",
    "                    min_samples_split=int(randomforest_cv_bo.max['params']['min_samples_split']),\n",
    "                    max_features=randomforest_cv_bo.max['params']['max_features'],\n",
    "                    random_state=0,\n",
    "                )\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        result = clf.predict(X_test)\n",
    "        profit, values = calc_profit(result, y_test)\n",
    "        precision = precision_score(y_test, result, average=None)\n",
    "        accuracy = accuracy_score(y_test, result)\n",
    "        confusion = confusion_matrix(y_test, result)\n",
    "        \n",
    "        print(clf.feature_importances_)\n",
    "        \n",
    "        if(1):\n",
    "        #if(precision[0]!=1 and precision[1]!=1 and abs(confusion[0][0]-confusion[1][1])<(confusion[0][0]+confusion[1][1])/4):\n",
    "        #if(precision[0]>0.4 and precision[1]>0.4):\n",
    "#             score = clf.score(X_test, y_test)\n",
    "            next_class.extend(clf.predict(X_next))\n",
    "\n",
    "            print('accuracy_score: ', end='')\n",
    "            print(accuracy_score(y_test, result))\n",
    "            accuracy_scores.extend([accuracy_score(y_test, result)])\n",
    "            print('confusion_matrix: ')\n",
    "            print(confusion_matrix(y_test, result))\n",
    "            print('precision_score: ', end='')\n",
    "            print(precision_score(y_test, result, average=None))\n",
    "            precision_scores.extend([precision_score(y_test, result, average=None)])\n",
    "\n",
    "            print(str(len(result))+\"hours trade\")\n",
    "            print(\"profit: \"+str(profit))\n",
    "\n",
    "            print('', flush=True)\n",
    "\n",
    "            model_name = moneyname + \"_\" + name + \"_\" + str(datanum) +\"_\"+str(accuracy)+\".sav\"\n",
    "            #clearlist.extend([model_name])\n",
    "            print(\"CLEAR: \" + model_name)\n",
    "            pickle.dump(clf, open(\"models/\"+model_name, 'wb'))\n",
    "\n",
    "    #print(clearlist)\n",
    "    return accuracy_scores, precision_scores, next_class, profit\n",
    "\n",
    "def make_models(test_minutes, namelist, moneylist, back_days, datanum):\n",
    "    for i in range(len(namelist)):\n",
    "        print(namelist[i], flush=True)\n",
    "        acc, pre, next_class, profit = predict(namelist[i], moneylist[i], test_minutes, back_days, datanum)\n",
    "        print(acc)\n",
    "\n",
    "\n",
    "def calc_profit(predict_result, true_data):\n",
    "    win=0\n",
    "    lose=0\n",
    "    for i in range(len(predict_result)):\n",
    "            if (predict_result[i]==-1):#Low予想のとき\n",
    "                if (predict_result[i]==true_data[i]): #予測成功\n",
    "                    win+=1\n",
    "                else:\n",
    "                    lose+=1\n",
    "            elif(predict_result[i]==1):#High予想の時\n",
    "                if (predict_result[i]==true_data[i]): #予測成功\n",
    "                    win+=1\n",
    "                else:\n",
    "                    lose+=1\n",
    "    profit = win*0.85-lose #利率を算出\n",
    "    values = predict_result*profit #予測結果×利率により予測の価値を算出\n",
    "    return profit, values\n",
    "\n",
    "def plot_result(index, predict_result, true_data):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    index = index.astype(float)\n",
    "\n",
    "    color = []\n",
    "    marker = []\n",
    "    accuracy = []\n",
    "    \n",
    "    for x in range(0,len(predict_result)):\n",
    "        if true_data.values[x] == predict_result[x]:\n",
    "            color.extend(['blue'])\n",
    "            accuracy.extend([1])\n",
    "        \n",
    "        elif predict_result[x]==0:\n",
    "            color.extend(['green'])\n",
    "            accuracy.extend([0])\n",
    "        else:\n",
    "            color.extend(['red'])\n",
    "            accuracy.extend([-1])\n",
    "\n",
    "\n",
    "    plt.scatter(index.index.values, index[\"Rate\"].values, color=color)\n",
    "\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def ensemble(model_names, moneyname, minutes):\n",
    "    \n",
    "\n",
    "    global PAGE\n",
    "    \n",
    "    temp = PAGE\n",
    "    #PAGE = trader.select_money(moneyname, temp)\n",
    "    \n",
    "    df_now = get_now_data(datetime.datetime.now(), period_minutes=minutes, money=moneyname, foot = FOOT, back_days = NIGHT)###########\n",
    "    print(\"money: \"+moneyname)\n",
    "    count = [0,0]\n",
    "    \n",
    "    #df_now['class'] = (df_now[\"Rate\"]).apply(lambda x: classify_two(x, count))\n",
    "    df_now['class'] = df_now['class'].shift(-1)\n",
    "    print(\"NOW Data from\" +str(days)+ \"days ago\")\n",
    "    print(\" LOW/MID/HIGH\")\n",
    "    print(count)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"test data\")\n",
    "    print(df_now.head(1).index.values,end=' to ')\n",
    "    print(df_now.tail(1).index.values)\n",
    "    print(\"\")\n",
    "    X_now = df_now.drop('class', axis=1)\n",
    "    \n",
    "    X_next = X_now.tail(1) #最終予測に利用\n",
    "    y_now = df_now['class']\n",
    "    X_now = X_now.drop(X_now.index[len(X_now)-1])\n",
    "    y_now = y_now.dropna()\n",
    "    \n",
    "    values = []\n",
    "    values_sum = []\n",
    "    win=0\n",
    "    lose=0\n",
    "    answer = 0\n",
    "    \n",
    "    #add DAY/2 前半でprecisionを作成、後半で実際の的中率を検討 ver3.1\n",
    "#     size = len(X_now)\n",
    "#     X_test = X_now.tail(int(size/2)-1)\n",
    "#     X_now = X_now.head(int(size/2))\n",
    "    \n",
    "#     y_test = y_now.tail(int(size/2)-1)\n",
    "#     y_now = y_now.head(int(size/2))\n",
    "    #print(len(X_test), len(y_test), len(X_now), len(y_now))\n",
    "    \n",
    "    \n",
    "    for x in range(len(model_names)):\n",
    "        clf = pickle.load(open(model_names[x], 'rb')) #clfをload\n",
    "        print(model_names[x], flush=True)\n",
    "        #result = clf.predict(X_now) #predict\n",
    "        #precision = precision_score(y_now, result, average=None)\n",
    "        #if(precision[0]!=0 and precision[1]!=0 and precision[0]!=1 and precision[1]!=1):\n",
    "        if(1):\n",
    "       \n",
    "            #score表示\n",
    "#             print(\"accuracy_score: \", end=\"\")\n",
    "#             accuracy = accuracy_score(y_now, result)\n",
    "#             print(accuracy)\n",
    "#             print(\"precision_score: \", end=\"\")\n",
    "#             print(precision)\n",
    "#             print(confusion_matrix(y_now, result))\n",
    "\n",
    "#             profit, values = calc_profit(result, y_now) #予測結果について利率と、予測*利率による予測の信頼性を算出\n",
    "            \n",
    "            \n",
    "            #answer += clf.predict(X_next)[0]*profit\n",
    "            answer += clf.predict(X_next)[0]\n",
    "            \n",
    "            result = clf.predict(X_now)\n",
    "             #predict\n",
    "            \n",
    "            ####valuesの算出方法で予測精度が決まる\n",
    "            \n",
    "            #values = result*accuracy #profit:-16\n",
    "            \n",
    "            #values = np.where(result<0, result*precision[0], result*precision[1]) #profit:-14\n",
    "            #values = result  #profit:-18\n",
    "            accuracy = accuracy_score(y_now, result)\n",
    "            print(accuracy)\n",
    "            values = result#*(1 - int(accuracy*100%2)*2)\n",
    "            \n",
    "#             plot_result(X_now, values, y_now)\n",
    "            \n",
    "#             print(\"profit: \",end='')\n",
    "#             profit, valuess = calc_profit(values, y_now)\n",
    "#             print(profit)\n",
    "            \n",
    "#             R=0.3  #R=0.37で-13.0,  R=0.35で-16 R=0.45で15, R=0.5で-15\n",
    "        \n",
    "#             if(precision[0]<R):\n",
    "#                 precision[0] = 0\n",
    "#             if(precision[1]<R):\n",
    "#                 precision[1] = 0\n",
    "#             values = np.where(result<0, result*precision[0], result*precision[1])\n",
    "\n",
    "            \n",
    "            #values = np.where(result<0, result*(((precision[0])*100)**2), (result*(((precision[1])*100)**2)))\n",
    "            \n",
    "            if len(values_sum)==0:#1回目は配列をコピー\n",
    "                values_sum = values\n",
    "            else:\n",
    "                values_sum += values #２回目からは加算\n",
    "            print(values)\n",
    "    \n",
    "        #plot_result(X_now, result, y_now)\n",
    "    if(answer>0):\n",
    "        print(\"HIGH\")\n",
    "        hl = \"HIGH\"\n",
    "        #trader.high_entry()\n",
    "        \n",
    "    else:\n",
    "        print(\"LOW\")\n",
    "        hl = \"LOW\"\n",
    "        #trader.low_entry()    \n",
    "    print(values_sum)\n",
    "    \n",
    "    if(values_sum==[]):\n",
    "        print(\"No model\")\n",
    "        return 0\n",
    "    \n",
    "    ensemble_result = np.where(values_sum<0, -1, 1) #クラス分類\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"ensemble_result: \",end='')\n",
    "    print(accuracy_score(y_now.values, ensemble_result))\n",
    "    print(ensemble_result)\n",
    "    print(y_now.values)\n",
    "    print(values_sum)\n",
    "    print(\"precision_score: \", end=\"\")\n",
    "    print(precision_score(y_now, ensemble_result, average=None))\n",
    "    print('confusion_matrix: ')\n",
    "    print(confusion_matrix(y_now, ensemble_result))\n",
    "    print(\"profit: \",end='')\n",
    "    profit, values = calc_profit(ensemble_result, y_now)\n",
    "    print(profit)\n",
    "    print(\"next: \",end='', flush=True)\n",
    "    print(answer)\n",
    "    \n",
    "    print(X_next.head(1))\n",
    "    accuracy = plot_result(X_now, ensemble_result, y_now)\n",
    "    \n",
    "    global profit_sum\n",
    "    profit_sum += profit\n",
    "    \n",
    "    global RESULT\n",
    "    RESULT.extend([moneyname+\": \"+hl])\n",
    "    return accuracy\n",
    "        \n",
    "    \n",
    "def compere_ensemble(models_array, moneys_array, minutes):\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(moneys_array)):\n",
    "        results.append(np.array(ensemble(models_array[i], moneys_array[i], minutes)).astype('int'))\n",
    "    \n",
    "    np.savetxt('out.csv',results,delimiter=',')\n",
    "    print(results)\n",
    "    \n",
    "def ensemble_set(models_array, moneys_array, minutes):\n",
    "    \n",
    "    for i in range(len(models_array)):\n",
    "        print(ensemble(models_array[i], moneys_array[i], minutes))    \n",
    "\n",
    "def plot_rates(hours, moneys):\n",
    "    \n",
    "    result = []\n",
    "    accord = []\n",
    "    plt.figure(figsize=(40,20))\n",
    "    for i in range(len(moneys)):\n",
    "#         df_now = get_now_data(datetime.datetime.now(), period_Days=days, money=moneys[i], foot = 'D', back_days = 0)\n",
    "        df_now = get_now_data(datetime.datetime.now(), period_days=days, money=moneys[i], foot = FOOT, back_days = 0)\n",
    "        plt.plot(df_now.index.values, df_now[\"Rate\"].values)\n",
    "        count = [0,0]\n",
    "        #df_now['class'] = (df_now[\"Rate\"]).apply(lambda x: classify_two(x, count))\n",
    "        result.append(df_now[\"class\"].values)\n",
    "    \n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    for l in range(len(result[0])):\n",
    "        temp = 0\n",
    "        for m in range(len(moneys)):\n",
    "            if result[m][l]==1:\n",
    "                temp+=1\n",
    "        if(temp==len(moneys)/2):\n",
    "            accord.extend([-1])\n",
    "            lose += len(moneys)/2\n",
    "            win += len(moneys)/2\n",
    "        else:\n",
    "            accord.extend([temp])\n",
    "            win += max(temp, len(moneys)-temp)\n",
    "            lose += min(temp, len(moneys)-temp)\n",
    "    \n",
    "    \n",
    "    plt.xticks(rotation=90)\n",
    "    plt.hlines([0], 0, days, \"blue\", linestyles='dashed')     # hlines\n",
    "    plt.show()\n",
    "    print(accord)\n",
    "    \n",
    "    pay = 1000\n",
    "    pay_sum = pay*len(moneys)\n",
    "    \n",
    "    print(\"win: \", win)\n",
    "    print(\"lose: \", lose)\n",
    "    print(\"rate: \", win/(win+lose))\n",
    "    print(\"profit: \", (win*0.85-lose)*pay_sum)\n",
    "\n",
    "COUNT = 0\n",
    "PAGE = 0\n",
    "    \n",
    "def job():\n",
    "    global COUNT\n",
    "    \n",
    "    time.sleep(5)\n",
    "    print(\"START\")\n",
    "    \n",
    "    if COUNT == 0:\n",
    "        print(\"Set up browser...\")\n",
    "        trader.setup_demo()\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        print(\"Ready for entry...\")\n",
    "        time.sleep(13)\n",
    "    main()\n",
    "    COUNT += 1\n",
    "    \n",
    "    #print(RESULT)\n",
    "    print('')\n",
    "    print(\"profit_sum: \", end='')\n",
    "    print(profit_sum)\n",
    "    RESULT = []\n",
    "#     print(\"Rebuild models...\")\n",
    "#     get_csv_and_make_models()\n",
    "    print('')\n",
    "    print('finished: ', end='')\n",
    "    print(datetime.datetime.now())\n",
    "    print('waiting...', flush=True)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    models = [glob.glob('models/USD_JPY*.sav'), glob.glob('models/EUR_JPY*.sav'), glob.glob('models/AUD_JPY*.sav'),\n",
    "              glob.glob('models/GBP_JPY*.sav'), glob.glob('models/NZD_JPY*.sav'), glob.glob('models/CAD_JPY*.sav'),\n",
    "              glob.glob('models/CHF_JPY*.sav')]#, glob.glob('ZAR_JPY*.sav')]\n",
    "    moneys = ['USD_JPY', 'EUR_JPY', 'AUD_JPY', 'GBP_JPY', 'NZD_JPY', 'CAD_JPY', 'CHF_JPY']#, 'ZAR_JPY']\n",
    "    \n",
    "    \n",
    "    #models = [glob.glob('models/USD_JPY*.sav'), glob.glob('models/EUR_USD*.sav'), glob.glob('models/EUR_JPY*.sav'), \n",
    "#               glob.glob('models/GBP_JPY*.sav'), glob.glob('models/AUD_JPY*.sav')]\n",
    "    #moneylist = ['USD_JPY', 'EUR_USD', 'EUR_JPY', 'GBP_JPY', 'AUD_JPY']\n",
    "    #ensemble(CHF_models, \"CHF_JPY\", 60)   #選択した通貨に対してアンサンブル\n",
    "    #compere_ensemble(models, moneys, 30)   #それぞれの通貨に対してアンサンブルした結果をcsvに返す\n",
    "    #plot_rates(30,moneys)\n",
    "    \n",
    "    ensemble_set(models, moneys, DAYS)  #指定したmoneyで結果を出す\n",
    "    print(RESULT)\n",
    "\n",
    "    print('')\n",
    "    print(\"profit_sum: \", end='')\n",
    "    print(profit_sum)\n",
    "    \n",
    "def get_csv_and_make_models():\n",
    "    \n",
    "    shutil.rmtree('csv')\n",
    "    shutil.rmtree('models')\n",
    "    \n",
    "    os.mkdir('csv')\n",
    "    os.mkdir('models')\n",
    "    \n",
    "    moneylist = ['USD_JPY', 'EUR_JPY', 'AUD_JPY', 'GBP_JPY', 'NZD_JPY', 'CAD_JPY', 'CHF_JPY']#, 'ZAR_JPY']\n",
    "    #moneylist = ['USD_JPY', 'EUR_USD', 'EUR_JPY', 'GBP_JPY', 'AUD_JPY']\n",
    "    \n",
    "#     array50 = get_moneys_csv(back_days=DAYS, days=50, moneylist = moneylist)\n",
    "#     array100 = get_moneys_csv(back_days=DAYS*2, minutes=100, moneylist = moneylist)\n",
    "#     array500 = get_moneys_csv(back_days=DAYS*2, days=500, moneylist = moneylist) # 指定期間のcsvをsave\n",
    "#     array1000 = get_moneys_csv(back_days=DAYS*2, minutes=1000, moneylist = moneylist)\n",
    "#     array1500 = get_moneys_csv(back_days=DAYS*2, days=1500, moneylist = moneylist)\n",
    "#     array2000 = get_moneys_csv(back_days=DAYS*2, days=2000, moneylist = moneylist)\n",
    "#     array2500 = get_moneys_csv(back_days=DAYS*2, days=2500, moneylist = moneylist)\n",
    "    array3000 = get_moneys_csv(back_days=DAYS*2, minutes=30000, moneylist = moneylist)\n",
    "    \n",
    "   #make_models(test_days, namelist, moneylist, back_days, datanum):\n",
    "    \n",
    "#     make_models(DAYS, array50, moneylist, 0, 50)\n",
    "#     make_models(MINUTES, array100, moneylist, DAYS, 100)\n",
    "#     make_models((DAYS), array500, moneylist, DAYS, 500)\n",
    "#     make_models(MINUTES, array1000, moneylist, DAYS, 1000)\n",
    "#     make_models((DAYS), array1500, moneylist, DAYS, 1500)\n",
    "#     make_models((DAYS), array2000, moneylist, DAYS, 2000)\n",
    "#     make_models((DAYS), array2500, moneylist, DAYS, 2500)\n",
    "    make_models(MINUTES, array3000, moneylist, DAYS, 30000)\n",
    "\n",
    "NIGHT = 0\n",
    "FOOT = 'M15'\n",
    "\n",
    "DAYS = 10\n",
    "\n",
    "MINUTES = DAYS*24*60\n",
    "\n",
    "PAST = 0\n",
    "\n",
    "\n",
    "get_csv_and_make_models()\n",
    "RESULT = []\n",
    "\n",
    "profit_sum = 0\n",
    "\n",
    "# now = datetime.datetime.now()\n",
    "# start_time = datetime.datetime(now.year, now.month, now.day, now.hour+1, 0, 0)\n",
    "# print((start_time-now).total_seconds()-10)\n",
    "# time.sleep((start_time-now).total_seconds()-10)\n",
    "\n",
    "\n",
    "#import trader\n",
    "#trader.setup_demo()\n",
    "main()\n",
    "#COUNT += 1\n",
    "# print(RESULT)\n",
    "# print('')\n",
    "# print(\"profit_sum: \", end='')\n",
    "# print(profit_sum)\n",
    "# print(\"pay 1000: \", end=str(profit_sum*1000))\n",
    "\n",
    "#schedule.every(60*59).seconds.do(job)\n",
    "\n",
    "print('Ready... :', end='')\n",
    "print(datetime.datetime.now())\n",
    "print(\"Did you restart the kernel?\")\n",
    "\n",
    "def auto():\n",
    "    schedule.every().day.at(\"07:00\").do(job)\n",
    "\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(5)\n",
    "\n",
    "# print(RESULT)\n",
    "\n",
    "# print('')\n",
    "# print(\"profit_sum: \", end='')\n",
    "# print(profit_sum)\n",
    "\n",
    "print(\"pay 1000: \", end=str(profit_sum*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
